{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>MC906/MO416 - Introduction to Artificial Intelligence</center>\n",
    "## <center>Institute of Computing - Unicamp</center>\n",
    "## <center>Prof. Esther Colombini</center>\n",
    "## <center>Project 1 - Deadline: 09/05/2020</center>\n",
    "\n",
    "#### Students:\n",
    "#### Eduardo S. Ito RA159086\n",
    "#### João Paulo RA ....\n",
    "#### Lucas Peres RA 265193\n",
    "#### Thales E. Nazatto RA 074388\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conteúdo\n",
    "\n",
    "1. Introdução\n",
    "    1. Descrição do problema\n",
    "2. Metodologia\n",
    "    1. Modelagem da solução\n",
    "        1. Requisitos\n",
    "        2. Implementação\n",
    "        3. Problema, agentes e ambiente\n",
    "    2. Algoritmos\n",
    "        1. Busca não-informada\n",
    "        2. Busca informada\n",
    "        3. Busca local (*Hill Climbing*)\n",
    "    3. Experimentos\n",
    "3. Resultados\n",
    "4. Conclusão\n",
    "5. Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Introdução\n",
    "**Pac-man** é um jogo para *Arcades* lançado em 1980 pela **Namco**, criado por Toru Iwatani e ilustrado na Figura 1. Nele, o jogador controla uma bolinha amarela (o *Pac-Man* do título) dentro de um labirinto que tem como objetivo comer todas as bolinhas brancas existentes nele enquanto é perseguido por 4 fantasmas de nomes *Blinky*, *Pinky*, *Inky* e *Clyde*. Na época, Iwatani criou o jogo para atrair pessoas de ambos os sexos, uma vez que os gêneros de jogos lançados nessa época, como jogos de guerra e esportes, eram majoritariamente pensados para agradar o público masculino. Tal estratégia se provou um grande sucesso, e *Pac-Man* se tornou uma das mais lucrativas franquias de todos os tempos, gerando mais de US$ 14 bilhões em receita até o ano de 2016 **[1]**.\n",
    "\n",
    "<img src=\"https://thumbs.web.sapo.io/?W=775&H=0&delay_optim=1&webp=1&epic=NGRiQ8y+7rDb2cocSbMwl47ynqxTFYLIDm2IhR5IZK5BFQooKY19ghBWe//2n+M5C2MgCiqhexDuDLBr/f/MrofnNA==\" height=\"240\" width=\"320\" alt=\"Tela do jogo Pac-Man\" title=\"Tela do jogo Pac-Man\" />\n",
    "<center><strong>Figura 1.</strong> Tela do jogo <i>Pac-Man</i></center>\n",
    "\n",
    "Uma dos grandes inovações para a época foi sua Inteligência Artificial. Cada fantasma se comportava de maneira diferente de acordo com os movimentos realizados pelo jogador, que poderiam ter a possibilidade de encurralá-lo. Enquanto *Blinky* perseguia *Pac-Man* diretamente, *Pinky* e *Inky* tentavam se posicionar a sua frente e *Clyde* alternava seus estados entre perseguir o *Pac-Man* e fugir dele. Tais comportamentos fizeram com que *Pac-Man* fosse um caso de estudos no ramo da Inteligência Artificial.\n",
    "\n",
    "Neste relatório, será mostrada uma modelagem do problema determinado em **[2]** utilizando 5 algoritmos de busca no contexto deste jogo, sendo 2 de busca não-informada (*Breadth-First Search* e *Depth-First Search*), 2 de busca informada (*Greedy Best-First Search* e *A*\\*) e 1 de busca local (*Hill Climbing*). Primeiro será detalhada como foi feita a modelagem do problema e as soluções aplicadas. Depois, serão feitos experimentos e dicussões para avaliar o comportamento dos algoritmos e, no final, as conclusões destes experimentos.\n",
    "\n",
    "### Descrição do problema\n",
    "\n",
    "Conforme determinado em **[2]**, o problema consiste em implementar 5 algoritmos diferentes de busca, sendo 2 de busca não-informada, 2 de busca informada (com 2 heurísticas diferentes) e 1 de busca local usando o *Pac-man* como tema, tendo como objetivo comer todas as bolinhas presentes no labirinto, caso consiga evitar os fantasmas. Dentre esses, é necessário avaliar critérios como otimalidade, completude e custo computacional para definir qual a melhor solução dentre elas.\n",
    "\n",
    "O labirinto é representado por um grid, também ilustrado na Figura 2, cujo tamanho e forma devem ser definidos. Deve ser definido também, além das posições das bolinhas que o *Pac-man* deve comer durante a execução do algoritmo, as posições de 3 fantasmas (que serão estáticos) e uma posição final de parada. É necessário especificar também a representação dos estados, as ações realizadas, o teste realizado para se chegar ao objetivo, o custo **g(x)** do caminho percorrido e as heurísticas utilizadas.\n",
    "\n",
    "<img src=\"https://shaunlebron.github.io/pacman-mazegen/img/origmaps_2x_print.png\" height=\"360\" width=\"480\" alt=\"Tela do jogo Pac-Man\" title=\"Tela do jogo Pac-Man\" />\n",
    "<center><strong>Figura 1.</strong> Exemplos de labirintos semelhantes <strong>[6]</strong></center>\n",
    "\n",
    "### Modelagem da solução\n",
    "\n",
    "#### Requisitos\n",
    "\n",
    "Dada a descrição do problema, foram levantados os seguintes requisitos para a conclusão deste projeto:\n",
    "\n",
    "- **[R1]** 2 algoritmos de busca não-informada\n",
    "- **[R2]** 2 algoritmos de busca informada (com 2 heurísticas diferentes)\n",
    "- **[R3]** 1 algoritmo de busca local\n",
    "- **[R4]** Definir como o problema é modelado\n",
    "- **[R5]** Especificações e restrições da aplicação\n",
    "- **[R6]** Avaliar custo computacional dos algoritmos\n",
    "- **[R7]** Avaliar completude dos algoritmos \n",
    "- **[R8]** Avaliar otimalidade dos algoritmos \n",
    "- **[R9]** Definir o tamanho e formato do labirinto\n",
    "- **[R10]** Definir uma posição final de parada\n",
    "- **[R11]** Definir as posições de 3 fantasmas (que serão estáticos)\n",
    "- **[R12]** Definir a posição inicial do *Pac-man*\n",
    "- **[R13]** Especificar representação dos estados\n",
    "- **[R14]** Especificar as ações realizadas\n",
    "- **[R15]** Especificar o teste realizado para se chegar ao objetivo\n",
    "- **[R16]** Especificar o custo **g(x)** do caminho percorrido\n",
    "- **[R17]** Especificar as heurísticas utilizadas\n",
    "- **[R18]** A posição inicial do *Pac-man* pode variar de acordo com o problema\n",
    "- **[R19]** A posição final de parada pode variar de acordo com o problema\n",
    "- **[R20]** Discretização dos estados (tamanho e configuração do labirinto)\n",
    "- **[R21]** As posições dos fantasmas podem variar de acordo com o problema\n",
    "- **[R22]** A busca não será *online*. O problema é completamente observável e determinístico\n",
    "\n",
    "#### Implementação\n",
    "\n",
    "Para a implementação, foi escolhido em vez da biblioteca AIMA **[3]** o código da Universidade de Berkeley **[4]**. Inicialmente a principal motivação de fazer a troca reside no fato que o código já possui as funções gráficas para exibição do problema, fazendo com que o foco das mudanças seja apenas na modelagem e nos algoritmos. Outras vantagens notadas é que a adaptação deste código para a representação de estados e ações foi mais simples e ele já possuía ferramentas para testes do objetivo. Entretanto, após informações futuras foi comprovado que não seria estritamente necessário e, como o Python 3 foi escolhido para a implementação, foram necessárias adaptações devido a diferenças na biblioteca *tkint* **[5]**. \n",
    "\n",
    "A principal mudança realizada em relação ao código original os arquivos **searchAgents.py** and **search.py**, que possuíam os códigos para modelagem dos agentes e para os algoritmos de busca, foram substituídos por versões customizadas, batizados de **search2Agents.py** and **search2.py** respectivamente. As configurações e usabilidade também foram herdadas do código da Universidade de Berkeley, sendo executadas na seção de Experimentos e discussão e utilizando estas *flags*:\n",
    "\n",
    "- **-l** - Determina o *layout* de labirinto a ser utilizado\n",
    "- **-p** - Determina o agente inteligente que controlará o *Pac-Man*\n",
    "- **-a** - Determina os parâmetros dos algoritmos utilizados. É possível selecionar o algoritmo utilizado (**fn**) e a heurística (**heuristic**)\n",
    "- **-z** - Zoom. Determina a escala da janela a ser aberta para visualização do jogo (de 0.1 a 0.9)\n",
    "\n",
    "Os labirintos são gerados em arquivos de texto, em arquivos de extensão **.lay**. Nele, o programa reconhece como códigos os seguintes caracteres:\n",
    "\n",
    "- **%** - Parede\n",
    "- **.** - Bolinha\n",
    "- **o** - Bolinha com poderes\n",
    "- **G** - Fantasma\n",
    "- **P** - *Pac-man*\n",
    "\n",
    "Tal padrão permite um desenvolvimento mais flexível e intuitivo dos labirintos, podendo colocar o *Pac-man*, os fantasmas e as bolinhas em diversas posições e com tamanhos e formatos variáveis de labirintos. Devido aos requisitos do projeto, foram colocadas as seguintes restrições:\n",
    "\n",
    "- Como o objetivo do problema prioriza a avaliação dos algoritmos, o problema foi modelado com o objetivo mais simples: Encontrar a única bolinha que está presente nos mapas propostos.\n",
    "- Não foram colocadas bolinhas com poderes nos labirintos. Isso dá mais ênfase a busca, pois o *Pac-man* sempre perderá o jogo se o algoritmo escolher o caminho onde está um dos fantasmas.\n",
    "- São colocados 3 fantasmas em posições determinadas, porém distintas.\n",
    "- O agente inteligente dos fantasmas é desligado durante o jogo.\n",
    "- Para simplificar os *layouts* e testes dos algoritmos, o labirinto possui o formato retangular e fechado.\n",
    "- O labirinto é feito em **[6]**, colocado em arquivo e possui um tamanho de 28 linhas x 31 colunas\n",
    "- O *Pac-man* é colocado em uma posição determinada.\n",
    "\n",
    "#### Problema, busca e agentes \n",
    "\n",
    "Como o labirinto é representado por um grid, os estados foram representados por tuplas no formato **(x,y)** e as ações são determinadas pelas direções **['South', 'West', 'East', 'North']**. Uma implementação simples do problema na biblioteca AIMA pode ser verificada no código abaixo:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"AIMA Library Representation similar to UC Berkeley code\"\"\"\n",
    "class SimplePacmanProblem(Problem):\n",
    "    def __init__(self, initial=(0, 0), goal=(30, 30), obstacles=(), heuristic=euclidean_distance, **kwds):\n",
    "        Problem.__init__(self, initial=initial, goal=goal, **kwds)\n",
    "        self.obstacles = obstacles - {initial, goal}\n",
    "        self.heuristic = heuristic\n",
    "\n",
    "    directions = [(0, -1), (-1, 0), (1, 0), (0, 1)]\n",
    "\n",
    "    def action_cost(self, s, action, s1): return self.heuristic(s, s1)\n",
    "\n",
    "    def value(self, state): return -1 * np.linalg.norm(self.heuristic(state, self.goal))\n",
    "\n",
    "    def h(self, node): return self.heuristic(node.state, self.goal)\n",
    "\n",
    "    def result(self, state, action):\n",
    "        return action if action not in self.obstacles else state\n",
    "\n",
    "    def actions(self, state):\n",
    "        x, y = state\n",
    "        return {(x + dx, y + dy) for (dx, dy) in self.directions} - self.obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nele, a classe **SimplePacmanProblem** é uma classe filha da classe **Problem**, que é passada para os algoritmos de busca encontrarem o melhor caminho. Como parâmetros em seu construtor há um valor inicial, final, obstáculos e heurística. **action_cost** é a função heurística utilizada para algoritmos de busca informada (ou **g(x)**), **h** é a função heurística utilizada para o *A*\\* (ou **h(x)**) e **value** é a função heurística utilizada para algoritmos de busca locais (ou **g(x)**). No AIMA, o heurística nos algoritmos de busca locais em seu código original é realizada em direção a um mínimo local. O valor de **directions** seria semelhante às ações que o *Pac-man* executaria no caminho, fazendo estados e ações serem tuplas no formato **(x,y)** e praticamente não tendo diferenciação.\n",
    "\n",
    "A classe semelhante no código utilizado neste projeto é a **PositionSearchProblem2**, que é uma classe filha da classe **SearchProblem2**, a qual é passada para os algoritmos de busca encontrarem o melhor caminho. Como parâmetros em seu construtor há um valor inicial, final, heurística e o estado do jogo, que guarda as posições das paredes, fantasmas, das bolinhas e do *Pac-man*. **getCostOfActions** é a função utilizada para determinar os estados através da função heurística para os algoritmos de busca informada e local (dependendo dos parâmetros utilizados pode ser **g(x)** ou **h(x)**). **getSuccessors** é a função que disponibiliza os nós sucessores da busca, semelhante a função **actions** presente na AIMA. Há ainda a função **isGoalState**, semelhante a função **goal_test** da classe **Problem**. A classe **Search2Agent** faz o papel de agente inteligente e a ligação entre problema, algoritmo de busca, estado do jogo e heurística.\n",
    "\n",
    "Um diagrama de classes com todas as classes presentes no código pode ser visto no PDF abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Eduardo\\Documents\\2020\\UNICAMP\\MO416A_AI\\Project1\\MO416AI-master\\Project1\\modelling\\modellingClasses.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This .pdf file shows class diagram that implements how the problem was modeled using game graphical interface. It is part\n",
    "# of how requirement [R4] and requirement [8] was modeling from Berkeley algorithm design base, and modification done\n",
    "# to comply with MO416 Project 1 requirements.\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd=cwd+'\\modelling\\modellingClasses.pdf'\n",
    "print(cwd)\n",
    "import webbrowser\n",
    "#webbrowser.open(r'file:///my_pdf.pdf')\n",
    "webbrowser.open(cwd)\n",
    "\n",
    "# Preconditions libraries: numpy and tkinter\n",
    "# pip install numpy\n",
    "# sudo apt-get update\n",
    "# sudo apt-get install python3.x-tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Algoritmos utilizados\n",
    "\n",
    "#### Busca não-informada\n",
    "\n",
    "#### Depth-First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function dfs\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "i=1,j=3\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 17), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 72 in 0.010737419128417969s\n",
      "Search nodes expanded: 79\n",
      "[R13] Nodes visited: [(23, 29), (22, 29), (21, 29), (20, 29), (19, 29), (18, 29), (17, 29), (16, 29), (15, 29), (14, 29), (13, 29), (12, 29), (11, 29), (10, 29), (9, 29), (8, 29), (7, 29), (6, 29), (5, 29), (4, 29), (3, 29), (2, 29), (1, 29), (1, 28), (1, 27), (1, 26), (1, 25), (1, 24), (1, 23), (1, 22), (1, 21), (1, 20), (2, 20), (3, 20), (4, 20), (5, 20), (6, 20), (6, 19), (6, 18), (6, 17), (6, 16), (5, 16), (4, 16), (3, 16), (2, 16), (1, 16), (1, 17), (1, 18), (1, 19), (3, 15), (3, 14), (3, 13), (2, 13), (1, 13), (1, 12), (1, 11), (1, 10), (2, 10), (3, 10), (3, 9), (3, 8), (3, 7), (2, 7), (1, 7), (4, 7), (5, 7), (6, 7), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R13] Solution states: 73 - [(23, 29), (22, 29), (21, 29), (20, 29), (19, 29), (18, 29), (17, 29), (16, 29), (15, 29), (14, 29), (13, 29), (12, 29), (11, 29), (10, 29), (9, 29), (8, 29), (7, 29), (6, 29), (5, 29), (4, 29), (3, 29), (2, 29), (1, 29), (1, 28), (1, 27), (1, 26), (1, 25), (1, 24), (1, 23), (1, 22), (1, 21), (1, 20), (2, 20), (3, 20), (4, 20), (5, 20), (6, 20), (6, 19), (6, 18), (6, 17), (6, 16), (5, 16), (4, 16), (3, 16), (3, 15), (3, 14), (3, 13), (2, 13), (1, 13), (1, 12), (1, 11), (1, 10), (2, 10), (3, 10), (3, 9), (3, 8), (3, 7), (4, 7), (5, 7), (6, 7), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R14] Solution actions: ['West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'East', 'East', 'East', 'East', 'East', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'South', 'South', 'South', 'East', 'East', 'South', 'South', 'South', 'East', 'East', 'East', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'North', 'North']\n",
      "Pacman emerges victorious! Score: 438\n",
      "Average Score: 438.0\n",
      "Scores:        438.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R1.1] Show dfs (depth first search) method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=dfs -z .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucas/mo416/MO416AI/Project1\n",
      "\n",
      "\n",
      "1. Modeling Proposal.\n",
      "\n",
      "function BREADTH_FIRST_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# The aim is to return a list of actions pacman to reach the goal (a food) by\n",
      "# searching the shallowest nodes or states in the search tree first.\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "queue := util.Queue();\n",
      "trace := empty list;\n",
      "seenList := empty list;\n",
      "\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "initial push on queue with start_state;\n",
      "Append (start_state) into seenList;\n",
      "\n",
      "while queue is not empty do\n",
      "\n",
      "   current_state := pop from queue;\n",
      "   \n",
      "   if goal state from problem is reached at current_state then  \n",
      "      break;\n",
      "   end if;\n",
      "   \n",
      "   successors := getSucccessors(current_state) from problem;\n",
      "   \n",
      "   for successor in successors do\n",
      "       next_state := state of successor;\n",
      "\t   next_action := action of successor;\n",
      "\t   \n",
      "\t   if next_state not in seenList then\n",
      "\t      Append(next_state) into seenList;\n",
      "\t\t  push(next_state) into queue;\n",
      "\t\t  trace[next_state] := with tuple (current_state, next_action);\n",
      "\t   end if;\n",
      "\n",
      "   end for;\n",
      "   \n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action := trace[backtrack_state];\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "function DEPTH_FIRST_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# The aim is to return a list of actions pacman to reach the goal (a food) by\n",
      "# searching the deepest nodes in the search tree first.\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "stack := get util.Stack();\n",
      "trace := get util.Stack();\n",
      "\n",
      "traveledList is empty initially;\n",
      "step_counter := 0\n",
      "\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "initial push stack with tuple (start_state, step_counter, 'START')\n",
      "\n",
      "while stack is not empty do\n",
      "   current_state, _, action := pop from stack;\n",
      "   Append (current_state) into traveledList;\n",
      "   \n",
      "   if action is not 'START' then\n",
      "      push (action) into trace list;\n",
      "\t  step_counter := step_counter + 1;\n",
      "   end if;\n",
      "   \n",
      "   if goal state from problem is reached at current_state then  \n",
      "      return trace list;\n",
      "   end if;\n",
      "   \n",
      "   valid_successors := 0;\n",
      "   successors := getSucccessors(current_state) from problem;\n",
      "   \n",
      "   for successor in successors do\n",
      "       next_state := state of successor;\n",
      "\t   next_action := action of successor;\n",
      "\t   \n",
      "\t   if next_state not in traveledList then\n",
      "\t      valid_successors := valid_successors + 1;\n",
      "\t\t  push the tuple (next_state, step_counter, next_action) into stack;\n",
      "\t   end if;\n",
      "   end for;\n",
      "   \n",
      "   if valid_successors is zero then\n",
      "      while step_counter is not stackList[-1][1] # back until next awaiting state do\n",
      "\t      setp_counter := step_counter - 1;\n",
      "\t\t  pop from trace list;\n",
      "\t  end while;\n",
      "   end if;\n",
      "\n",
      "end while\n",
      "}\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "function A_STAR_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# the pacman goal is to get the food at n-interactions with cost f(n) = h(n)\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "openList := class PriorityQueue();\n",
      "g := empty list; # step cost\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "Define function f(current_state) returns g[current_state] + manhattanHeuristic(current_state, problem);\n",
      "g[start_state] := 0; # cost 0 initially\n",
      "Push(start_state, 0) into openList;\n",
      "start openSeen list;\n",
      "close_list := empty list;\n",
      "trace := empty list;\n",
      "trace[start_state] := a tuple with [None, None, 0]\n",
      "\n",
      "while openList is not empty do\n",
      "    current_state := get popping open_list;\n",
      "\tremove (current_state) from openSeen list;\n",
      "\tif goal in problem is reached at current_state then break;\n",
      "\t\n",
      "\tsuccessors := getSuccessors from current_state in problem;\n",
      "\t\n",
      "\tfor successor in successors do\n",
      "\t    next_state := state from successor;\n",
      "\t\tnext_action = action from successor;\n",
      "\t\tnext_cost := cost from successor;\n",
      "\t\tsuccessor_cost := g[current_state] + next_cost;\n",
      "\t\t\n",
      "\t    UPDATE status := False;\n",
      "\t\tif next_state in openSeen list do\n",
      "\t\t   if g[next_state] =< successor_cost then pass;\n",
      "\t\t   else do\n",
      "\t\t           g[next_state] =< successor_cost;\n",
      "\t\t\t\t   Update openList with item=next_state and priority=f(next_state);\n",
      "\t\t        end do \n",
      "\t\t   else if next_state in close_list do\n",
      "\t\t        if g[next_state] =< successor_cost then pass;\n",
      "\t\t\t\telse UPDATE status := True;\n",
      "\t\t\t\tend if\n",
      "\t\t   else: UDPATE status := True\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\tif UPDATE status is True then\n",
      "\t\t   g[next_state] := succcessor_cost;\n",
      "\t\t   openList update with item=next_state and priority=f(next_state)\n",
      "\t\t   Append (next) into openSeen;\n",
      "\t\t   \n",
      "\t\t   if next_state in close_list then\n",
      "\t\t      remove(next_state) from close_list;\n",
      "\t\t\t  remove(next_state) from openSeen\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t# update and allow tracing to the best state\n",
      "\t\tif next_state in trace then\n",
      "\t\t   if cost in trace[next_state] > successor_cost then\n",
      "\t\t      trace[next_state] state := current_state;\n",
      "\t\t\t  trace[next_state] := next_action;\n",
      "\t\t\t  trace[next_state] cost := successor_cost;\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t\n",
      "\tend for;\n",
      "\t\n",
      "\tAppend(current_state) into close_list;\n",
      "\n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "function A_STAR_EUCLIDEAN_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# the pacman goal is to get the food at n-interactions with cost f(n) = h(n)\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "openList := class PriorityQueue();\n",
      "g := empty list; # step cost\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "Define function f(current_state) returns g[current_state] + euclideanHeuristic(current_state, problem);\n",
      "g[start_state] := 0; # cost 0 initially\n",
      "Push(start_state, 0) into openList;\n",
      "start openSeen list;\n",
      "close_list := empty list;\n",
      "trace := empty list;\n",
      "trace[start_state] := a tuple with [None, None, 0]\n",
      "\n",
      "while openList is not empty do\n",
      "    current_state := get popping open_list;\n",
      "\tremove (current_state) from openSeen list;\n",
      "\tif goal in problem is reached at current_state then break;\n",
      "\t\n",
      "\tsuccessors := getSuccessors from current_state in problem;\n",
      "\t\n",
      "\tfor successor in successors do\n",
      "\t    next_state := state from successor;\n",
      "\t\tnext_action = action from successor;\n",
      "\t\tnext_cost := cost from successor;\n",
      "\t\tsuccessor_cost := g[current_state] + next_cost;\n",
      "\t\t\n",
      "\t    UPDATE status := False;\n",
      "\t\tif next_state in openSeen list do\n",
      "\t\t   if g[next_state] =< successor_cost then pass;\n",
      "\t\t   else do\n",
      "\t\t           g[next_state] =< successor_cost;\n",
      "\t\t\t\t   Update openList with item=next_state and priority=f(next_state);\n",
      "\t\t        end do \n",
      "\t\t   else if next_state in close_list do\n",
      "\t\t        if g[next_state] =< successor_cost then pass;\n",
      "\t\t\t\telse UPDATE status := True;\n",
      "\t\t\t\tend if\n",
      "\t\t   else: UDPATE status := True\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\tif UPDATE status is True then\n",
      "\t\t   g[next_state] := succcessor_cost;\n",
      "\t\t   openList update with item=next_state and priority=f(next_state)\n",
      "\t\t   Append (next) into openSeen;\n",
      "\t\t   \n",
      "\t\t   if next_state in close_list then\n",
      "\t\t      remove(next_state) from close_list;\n",
      "\t\t\t  remove(next_state) from openSeen\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t# update and allow tracing to the best state\n",
      "\t\tif next_state in trace then\n",
      "\t\t   if cost in trace[next_state] > successor_cost then\n",
      "\t\t      trace[next_state] state := current_state;\n",
      "\t\t\t  trace[next_state] := next_action;\n",
      "\t\t\t  trace[next_state] cost := successor_cost;\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t\n",
      "\tend for;\n",
      "\t\n",
      "\tAppend(current_state) into close_list;\n",
      "\n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "-----------------------------------------------------------------------------------\n",
      "function GREEDY_BEST_FIRST_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# the pacman goal is to get the food at n-interactions with cost f(n) = g(n) + h(n)\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "openList := class PriorityQueue();\n",
      "g := empty list; # step cost\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "Define function f(current_state) returns manhattanHeuristic(current_state, problem);  # difference from A* is only here\n",
      "g[start_state] := 0; # cost 0 initially\n",
      "Push(start_state, 0) into openList;\n",
      "start openSeen list;\n",
      "close_list := empty list;\n",
      "trace := empty list;\n",
      "trace[start_state] := a tuple with [None, None, 0]\n",
      "\n",
      "while openList is not empty do\n",
      "    current_state := get popping open_list;\n",
      "\tremove (current_state) from openSeen list;\n",
      "\tif goal in problem is reached at current_state then break;\n",
      "\t\n",
      "\tsuccessors := getSuccessors from current_state in problem;\n",
      "\t\n",
      "\tfor successor in successors do\n",
      "\t    next_state := state from successor;\n",
      "\t\tnext_action = action from successor;\n",
      "\t\tnext_cost := cost from successor;\n",
      "\t\tsuccessor_cost := g[current_state] + next_cost;\n",
      "\t\t\n",
      "\t    UPDATE status := False;\n",
      "\t\tif next_state in openSeen list do\n",
      "\t\t   if g[next_state] =< successor_cost then pass;\n",
      "\t\t   else do\n",
      "\t\t           g[next_state] =< successor_cost;\n",
      "\t\t\t\t   Update openList with item=next_state and priority=f(next_state);\n",
      "\t\t        end do \n",
      "\t\t   else if next_state in close_list do\n",
      "\t\t        if g[next_state] =< successor_cost then pass;\n",
      "\t\t\t\telse UPDATE status := True;\n",
      "\t\t\t\tend if\n",
      "\t\t   else: UDPATE status := True\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\tif UPDATE status is True then\n",
      "\t\t   g[next_state] := succcessor_cost;\n",
      "\t\t   openList update with item=next_state and priority=f(next_state)\n",
      "\t\t   Append (next) into openSeen;\n",
      "\t\t   \n",
      "\t\t   if next_state in close_list then\n",
      "\t\t      remove(next_state) from close_list;\n",
      "\t\t\t  remove(next_state) from openSeen\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t# update and allow tracing to the best state\n",
      "\t\tif next_state in trace then\n",
      "\t\t   if cost in trace[next_state] > successor_cost then\n",
      "\t\t      trace[next_state] state := current_state;\n",
      "\t\t\t  trace[next_state] := next_action;\n",
      "\t\t\t  trace[next_state] cost := successor_cost;\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t\n",
      "\tend for;\n",
      "\t\n",
      "\tAppend(current_state) into close_list;\n",
      "\n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "function GREEDY_BEST_FIRST_EUCLIDEAN_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# the pacman goal is to get the food at n-interactions with cost f(n) = g(n) + h(n)\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "openList := class PriorityQueue();\n",
      "g := empty list; # step cost\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "Define function f(current_state) returns euclideanHeuristic(current_state, problem);  \n",
      "                                                    # difference from A* is only here\n",
      "g[start_state] := 0; # cost 0 initially\n",
      "Push(start_state, 0) into openList;\n",
      "start openSeen list;\n",
      "close_list := empty list;\n",
      "trace := empty list;\n",
      "trace[start_state] := a tuple with [None, None, 0]\n",
      "\n",
      "while openList is not empty do\n",
      "    current_state := get popping open_list;\n",
      "\tif current_state is in openSeen then\n",
      "\t   remove (current_state) from openSeen list;\n",
      "\tend if;\n",
      "\tif goal in problem is reached at current_state then break;\n",
      "\tend if;\n",
      "\tsuccessors := getSuccessors from current_state in problem;\n",
      "\t\n",
      "\tfor successor in successors do\n",
      "\t    next_state := state from successor;\n",
      "\t\tnext_action = action from successor;\n",
      "\t\tnext_cost := cost from successor;\n",
      "\t\tsuccessor_cost := g[current_state] + next_cost;\n",
      "\t\t\n",
      "\t    UPDATE status := False;\n",
      "\t\tif next_state in openSeen list do\n",
      "\t\t   if g[next_state] =< successor_cost then pass;\n",
      "\t\t   else do\n",
      "\t\t           g[next_state] =< successor_cost;\n",
      "\t\t\t\t   Update openList with item=next_state and priority=f(next_state);\n",
      "\t\t        end do \n",
      "\t\t   else if next_state in close_list do\n",
      "\t\t        if g[next_state] =< successor_cost then pass;\n",
      "\t\t\t\telse UPDATE status := True;\n",
      "\t\t\t\tend if\n",
      "\t\t   else: UDPATE status := True\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\tif UPDATE status is True then\n",
      "\t\t   g[next_state] := succcessor_cost;\n",
      "\t\t   openList update with item=next_state and priority=f(next_state)\n",
      "\t\t   Append (next) into openSeen;\n",
      "\t\t   \n",
      "\t\t   if next_state in close_list then\n",
      "\t\t      remove(next_state) from close_list;\n",
      "\t\t\t  remove(next_state) from openSeen\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t# update and allow tracing to the best state\n",
      "\t\tif next_state in trace then\n",
      "\t\t   if cost in trace[next_state] > successor_cost then\n",
      "\t\t      trace[next_state] state := current_state;\n",
      "\t\t\t  trace[next_state] := next_action;\n",
      "\t\t\t  trace[next_state] cost := successor_cost;\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t\n",
      "\tend for;\n",
      "\t\n",
      "\tAppend(current_state) into close_list;\n",
      "\n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "function HILL-CLIMBING(problem) returns a list of actions towards the pacman goal {\n",
      "# the top of hill is the pacman goal\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (current node) and next_state (a neighbor)\n",
      "priority_queue := class PriorityQueue();\n",
      "priority_queue.update(start_state);\n",
      "current_state := CREATE-NODE(START-STATE[problem]);\n",
      "prev_cost := 0;\n",
      "trace[start_state] := tuple of (none state, none action, prev_cost)\n",
      "veryPreviousSuccessor:=empty;\n",
      "prevsuccessor := empty; # previous successor;\n",
      "\n",
      "while not priority_queue.isEmpty do\n",
      "   current_state := priority_queue.pop();\n",
      "   \n",
      "   if problem goal is current_state state then end while;\n",
      "   \n",
      "   successors := problem.getSuccessors(current_state); # a pacman sucessor can be \n",
      "                             # any next position at North, South, \n",
      "\t\t\t                 # East, West. Making sure  that                 \n",
      "\t\t                     # previous position is not allowed.\n",
      "\t\t\t\t\t\t     # and if there are more than one of successors \n",
      "\t\t\t\t\t\t\t # is selected at random, as cost of any \n",
      "\t\t\t\t\t\t\t # step in pacman is unique.\n",
      "   \n",
      "\tt := length of successors # amount of successors;\n",
      "\tselectedSuccessor=[];\n",
      "\tif t is 1, i.e. unique successor then\n",
      "\t   index := 0;\n",
      "\t   selectedSuccessor := successors;\n",
      "\telse\n",
      "\t   i := 0;\n",
      "\n",
      "\t while True:\n",
      "\t   i := i+1;\n",
      "\t   index := choose at random in between 0 and t-1;\n",
      "\t   if previousSuccessor is [] then\n",
      "\t      selectedSuccessor := successors[index];\n",
      "\t\t  prevsuccessor := selectedSuccessor;\n",
      "\t\t  break;\n",
      "\t   if state in successors[index] not equal to state in previousSuccessor then\n",
      "\t      if (not(action='East' in successors[index] and action='West' in previousSuccessor[index]\n",
      "\t\t       or action='West' in successors[index] and action='East' in previousSuccessor[index]\n",
      "\t\t\t   or action='South' in successors[index] and action='North' in previousSuccessor[index]\n",
      "\t\t\t   or action='North' in successors[index] and action='South' in previousSuccessor[index]))\n",
      "\t\t\t   then \n",
      "\t\t\t       selectedSuccessor := successors[index];\n",
      "\t\t\t\t   previousSuccessor := selectedSuccessor;\n",
      "\t\t\t\t   break; # exit from while True\n",
      "       if (i>5) then # if more than 5 attempts\n",
      "\t      index := get a number at random in between 0 and t-1; # choose a successor at random\n",
      "\t\t  selectedSuccessor := successors[index];\n",
      "\t\t  previousSuccessor := selectedSuccessor;\n",
      "\t\n",
      "\t for successor in selectedSuccessor do\n",
      "\t\tnext_state = state of successor; # node\n",
      "\t\tnext_action = action of successor; # if west, east, north, sourth\n",
      "\t\tnext_cost = cost of successor; # always 1\n",
      "\t     \n",
      "\t\tif veryPreviousSuccessor is empty then \n",
      "\t\t   veryPreviousSuccessor := successor;\n",
      "\t\t   prev_cost := cost of trace[current_state];\n",
      "\t\t   priority_queue update with next_state;\n",
      "\t\telse if (not(action='East' in successors[index] and action='West' in previousSuccessor[index]\n",
      "\t\t       or action='West' in successors[index] and action='East' in previousSuccessor[index]\n",
      "\t\t\t   or action='South' in successors[index] and action='North' in previousSuccessor[index]\n",
      "\t\t\t   or action='North' in successors[index] and action='South' in previousSuccessor[index]))\n",
      "\t\t\t   then\n",
      "\t\t\t      veryPreviousSuccessor := successor;\n",
      "\t\t\t\t  prev_cost := cost of trace[current_state];\n",
      "\t\t\t\t  priority_queue update with next_state;\n",
      "\t\tend if\n",
      "\t\t\t\t  \n",
      "\t\tif next_state is not in the trace then\n",
      "\t\t   trace[next_state] := tuple of [current_state, next_action, 1]\n",
      "\t\tend if\n",
      "\tend while\n",
      "end while\n",
      "\n",
      "actions list := an empty list;\t   \n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_start do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) to actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "function MANHATTAN_HEURISTIC(position, problem) returns a absolute value float {\n",
      "# The aim is to return a list of actions pacman to reach the goal (a food) by\n",
      "# searching the shallowest nodes or states in the search tree first.\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState), position\n",
      "xy1 := position;\n",
      "xy2 := problem.goalState;\n",
      "# xy1, xy2 are in coordinated axis (i, j)\n",
      "\n",
      "return absolute value (xy1(i,) - xy2(i,) + absolute value (xy1(,j)- xy2(,j))\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "function EUCLIDEAN_HEURISTIC(position, problem) returns a absolute value float {\n",
      "# The aim is to return a list of actions pacman to reach the goal (a food) by\n",
      "# searching the shallowest nodes or states in the search tree first.\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState), position\n",
      "xy1 := position;\n",
      "xy2 := problem.goalState;\n",
      "# xy1, xy2 are in coordinated axis (i, j)\n",
      "\n",
      "return int(( (xy1(i,) - xy2(i,)) ** 2 + (xy1(,j) - xy2(,j)) ** 2 ) ** 0.5)\n",
      "\n",
      "-----------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHAPTER 1: REQUIREMENT SPECIFICATION\n",
    "\n",
    "# 1. Goal\n",
    "\n",
    "# [R1] Two search methods without information\n",
    "# [R2] Two informed search methods with 2 distinct heuristics\n",
    "# [R3] One local search method\n",
    "\n",
    "# The work consists of finding an adequate solution to the chosen problem, evaluating it according to: computational\n",
    "#cost, completeness, optimality. Your are required to clearly define:\n",
    "\n",
    "# [R4] How the problem was modeled\n",
    "# [R5] Implementation specifics and restrictions\n",
    "\n",
    "# The work consists of ending an adequate solution to the chosen problem, evaluating it according to: [R6]computational\n",
    "# cost, [R7] completeness, [R24] optimality. Your are required to clearly define:\n",
    "# [R8] How the problem was modeled\n",
    "# [R5] Implementation specifics and restrictions\n",
    "\n",
    "# 2. Problem\n",
    "# Pac-man is one of the most popular Arcade games, still played nowadays. In the game, there is a maze where Pac-man\n",
    "# has to act to collect as many pieces as possible without being caught by one of the ghosts. The maze is defined in\n",
    "# terms of a grid, as presented in Figure 1. The black areas are non-traversable walls, the grey path represents elements\n",
    "# that should be caught by the agent, and the white areas are traversable areas. Your group should define additional\n",
    "# elements, such as:\n",
    "\n",
    "# [R10] The size and shape of the maze\n",
    "# [R11] A final goal position\n",
    "# [R12] The static positions of 3 Ghosts in the scene (the positions do not change during the game)\n",
    "# [R13] Pac-man's initial position\n",
    "\n",
    "# To solve the problem, you have to specify:\n",
    "\n",
    "# [R14] The state representation\n",
    "# [R15] The set of actions\n",
    "# [R16] The objective state test\n",
    "# [R17] The cost of the path (g(x))\n",
    "# [R18] The heuristics used\n",
    "\n",
    "# The system must be evaluated according to the quality of the solutions found and a critical evaluation is expected on\n",
    "# the relationship between adopted parameters x solution performance. Graphs and tables representing the evolution of\n",
    "# the solutions are expected. Additional comparisons with the literature are welcome, although they are not mandatory.\n",
    "# To evaluate the results you might change the following elements:\n",
    "\n",
    "# [R19] Pac-man's initial position\n",
    "# [R20] Goal position\n",
    "# [R21] State discretization (maze size and configuration)\n",
    "# [R22] Ghosts' position\n",
    "\n",
    "# [R23] It is important to remember that we will not perform an online search. As the problem is completely observable and\n",
    "# deterministic, Pac-man is going to reason about the solution before actually adopting it.\n",
    "\n",
    "# CHAPTER 2: MODELING PROPOSAL\n",
    "\n",
    "# Chapter 2.1 [R4] How the Problem was modelled?\n",
    "# The Berkeley algorithm algorithm was used as design base for our implementation.\n",
    "#        Artificial Intelligence in Pacman Class material offered in the course \n",
    "#        \"Artificial Intelligence (2019 Spring) of NTU\" at url https://github.com/andi611/Pacman-With-AI-Python.\n",
    "#        The reason was to comply with [R10]..[R13], it was understood that graphical interface is required, at initial\n",
    "#        stage of project. Despite, the classroom on April 29th, it was clarified that it was not required.\n",
    "#\n",
    "# The reason why requirement [4] Python implementation of algorithms from Russell And Norvig's \"Artificial Intelligence\n",
    "#        - A Modern Approach\"  https://github.com/aimacode/aima-python, was not used, is that Berkeley algorithm and Node \n",
    "#        library as used by Russell and Norvig are incompatible. The state used by them differs on coordinate axis\n",
    "#        and the integration of graphical interface and list of actions produced by search algorithm could take very long,\n",
    "#        and could become unfeasible to comply with mostly of requirements, in time. Berkeley algorithms use Game library,\n",
    "#        and Russell and Norvig algorithms use Node library. More differences will be explained on this report.This is also\n",
    "#        for sake of requirement [5] reporting limitations.\n",
    "#\n",
    "# Our  Project Repository is stored at folder Prototype3, only this, at github address https://github.com/edbkei/MO416AI\n",
    "#\n",
    "# For sake of operationally, the command line inherited \"partly\" by Berkeley algorithm our pacman use cases, do the following: \n",
    "#        !python pacman.py -l layoutMO416b -p Search2Agent -a fn=<fn> -z <z>\n",
    "#        -l layout parameter. We use only the layoutMO416b, nevertheless others are allowed, still.\n",
    "#        -p agent parameter. We use only Search2Agent as the manager for accessing search methods existing in search2.py,\n",
    "#                            accordingly to problem concept and parameter -a selection. SearchAgents.py and search.py\n",
    "#                            were used as design base.\n",
    "#        -a search method. We use dfs (depth-first search ), ucs (uniform cost search), bfs (breadth-first search), \n",
    "#                          astar (A* with Manhattan Heuristic), gbfs (greedy best fisrt search with Manhattan Heuristic), \n",
    "#                          astare (A* with Euclidean Heuristic), gbfes (greedy best fisrt search with Euclidean Heuristic), \n",
    "#                          and hcs (hill climbing search, local search),\n",
    "#\n",
    "#                          The design base had already dfs, ucs, bfs, astar (with null heuristic), not existed before\n",
    "#                          gbfs neither hcs.\n",
    "#\n",
    "#        -z zoom. Numberic value (0.1..0.9)\n",
    "#\n",
    "# Conversion from Python 2.7 to Python 3.4. Fix several incompatibility as print format, and library tkint.\n",
    "#        https://docs.python.org/3/library/tkinter.html. This is also to report constraint as requested by requirement [5].\n",
    "#\n",
    "# We customized Berkeley algorithm, accordingly to following:\n",
    "#       The implementation of requirement [R10] with maze were done by customization of maze generated by\n",
    "#       https://shaunlebron.github.io/packman-mazegen. We included initial pacman position, only an unique food,\n",
    "#       3 ghosts located in random positions in the maze. Our maze is called layoutMO416b.lay, as the format understood by\n",
    "#       Berkeley format. It is located at ../MO416AI/Prototype3/layout.\n",
    "#       The requirement [R10] is implemented with maze represented by the file. \n",
    "#       The requirement [R10] about size and shape are inherited by Berkeley algorithm. The command parameter -z\n",
    "#       makes zoom possible. \n",
    "#\n",
    "#       The requirement [R11] is implemented as output in search2Agents.py\n",
    "#       The requirement [R12] is implemented by means of pause in the dynamicity of ghost on script pacman.py\n",
    "#       The requirement [R13] is implemented as output in search2Agents.py\n",
    "#       The requirement [R16] is implemented as output in search2Agents.py\n",
    "#       The requirement [R17] is implemented as output in search2Agents.py\n",
    "#       The requirement [R18] is complied with euclidean and Manhattan heuristic from design base, but not used\n",
    "#       in our use cases. We implemented manhattan and euclidean heuristic (h) for A* and gbfs, in hard code way.\n",
    "#       The original algorithm of A* considers the stop condition f(x)=g(x)+h(x) with null heuristic, \n",
    "#       and we did the same algorithm as A* but with f(x) = h(x) for gbfs. We implemented in search2Agents.py and search2.py.\n",
    "#       The hill climbing search was created from the scratch.\n",
    "#       The requirement [R20] is implemented in the class PositionSearchProblem2, in search2Agents.py, using the\n",
    "#       the methods gameState.getFood and gamestate.hasFood. Now, it is possible to put food, but only one, in any place of\n",
    "#       the maze.\n",
    "#\n",
    "#       New function codes to make possible to specify parameter value gbfs and hcs in the command line were introduced. \n",
    "#       Implemented in search2.py.\n",
    "#\n",
    "#      The requirement [R14], also part of requirement [8], is implemented by the concept of problem used by Berkeley\n",
    "#      algorithm is PositionSearchProblem2 (similar to original PositionSearchProblem, but with additions herein explanained).\n",
    "#      It is a tuple of (initial state position of the pacman, the goal position of the food, \n",
    "#      action (if next step of pacman is east, west, north, south), cost of 1 for each step in the maze)\n",
    "#\n",
    "#      When a command line is issued, search2Agents is invoked, and according to function code, the PositionSearchProblem2 \n",
    "#      class is invoked to build an actions list produced by search method (in search2.py). Owning this list, \n",
    "#      the class search2Agents can send it to game graphics interface.\n",
    "#      \n",
    "#      For sake of clarity, despite inherited algorithm from Berkeley, the used classes will be represented in class diagram,\n",
    "#      by customization of pyreverse output.\n",
    "#\n",
    "#      And the used search methods are described in high level algorithms. See more in modelingProposal at item [11].\n",
    "#      \n",
    "#      The requirement [21] is implemented in design base of Berkeley algorithm, and -z parameter (zoom). It is also\n",
    "#      implemented layout.py and layout data in format .lay.\n",
    "#\n",
    "#      The requirement [R23] is already implemented from design base of Berkeley algorithm. Basically, depending on use case \n",
    "#      defined by commmand line, where search method, and layout chosen. The search methods return actions list where pacman\n",
    "#      should pass by from start state to goal state. This actions list is submitted to graphical interface that runs pacman\n",
    "#      game.\n",
    "#\n",
    "#      Modeling version information is given here https://github.com/edbkei/MO416AI, at README.\n",
    "\n",
    "\n",
    "# Methods used in search2.py. It complements the requirement [R14] to represent the state representation\n",
    "# and requirement [R15] The set of actions. Also it also complies to requirement [8].\n",
    "#\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "cwd=cwd+'/modelling/modellingProposal'\n",
    "f = open(cwd, 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelagem da solução\n",
    "\n",
    "#### Requisitos\n",
    "\n",
    "Dada a descrição do problema, foram levantados os seguintes requisitos para a conclusão deste projeto:\n",
    "\n",
    "- **[R1]** 2 algoritmos de busca não-informada\n",
    "- **[R2]** 2 algoritmos de busca informada (com 2 heurísticas diferentes)\n",
    "- **[R3]** 1 algoritmo de busca local\n",
    "- **[R4]** Definir como o problema é modelado\n",
    "- **[R5]** Especificações e restrições da aplicação\n",
    "- **[R6]** Avaliar custo computacional dos algoritmos\n",
    "- **[R7]** Avaliar completude dos algoritmos \n",
    "- **[R8]** Avaliar otimalidade dos algoritmos \n",
    "- **[R9]** Definir o tamanho e formato do labirinto\n",
    "- **[R10]** Definir uma posição final de parada\n",
    "- **[R11]** Definir as posições de 3 fantasmas (que serão estáticos)\n",
    "- **[R12]** Definir a posição inicial do *Pac-man*\n",
    "- **[R13]** Especificar representação dos estados\n",
    "- **[R14]** Especificar as ações realizadas\n",
    "- **[R15]** Especificar o teste realizado para se chegar ao objetivo\n",
    "- **[R16]** Especificar o custo **g(x)** do caminho percorrido\n",
    "- **[R17]** Especificar as heurísticas utilizadas\n",
    "- **[R18]** A posição inicial do *Pac-man* pode variar de acordo com o problema\n",
    "- **[R19]** A posição final de parada pode variar de acordo com o problema\n",
    "- **[R20]** Discretização dos estados (tamanho e configuração do labirinto)\n",
    "- **[R21]** As posições dos fantasmas podem variar de acordo com o problema\n",
    "- **[R22]** A busca não será *online*. O problema é completamente observável e determinístico\n",
    "\n",
    "#### Implementação\n",
    "\n",
    "Para a implementação, foi escolhido em vez da biblioteca AIMA **[3]** o código da Universidade de Berkeley **[4]**. Inicialmente a principal motivação de fazer a troca reside no fato que o código já possui as funções gráficas para exibição do problema, fazendo com que o foco das mudanças seja apenas na modelagem e nos algoritmos. Outras vantagens notadas é que a adaptação deste código para a representação de estados e ações foi mais simples e ele já possuía ferramentas para testes do objetivo. Entretanto, após informações futuras foi comprovado que não seria estritamente necessário e, como o Python 3 foi escolhido para a implementação, foram necessárias adaptações devido a diferenças na biblioteca *tkint* **[5]**. \n",
    "\n",
    "A principal mudança realizada em relação ao código original os arquivos **searchAgents.py** and **search.py**, que possuíam os códigos para modelagem dos agentes e para os algoritmos de busca, foram substituídos por versões customizadas, batizados de **search2Agents.py** and **search2.py** respectivamente. As configurações e usabilidade também foram herdadas do código da Universidade de Berkeley, sendo executadas na seção de Experimentos e discussão e utilizando estas *flags*:\n",
    "\n",
    "- **-l** - Determina o *layout* de labirinto a ser utilizado\n",
    "- **-p** - Determina o agente inteligente que controlará o *Pac-Man*\n",
    "- **-a** - Determina os parâmetros dos algoritmos utilizados. É possível selecionar o algoritmo utilizado (**fn**) e a heurística (**heuristic**)\n",
    "- **-z** - Zoom. Determina a escala da janela a ser aberta para visualização do jogo (de 0.1 a 0.9)\n",
    "\n",
    "Os labirintos são gerados em arquivos de texto, em arquivos de extensão **.lay**. Nele, o programa reconhece como códigos os seguintes caracteres:\n",
    "\n",
    "- **%** - Parede\n",
    "- **.** - Bolinha\n",
    "- **o** - Bolinha com poderes\n",
    "- **G** - Fantasma\n",
    "- **P** - *Pac-man*\n",
    "\n",
    "Tal padrão permite um desenvolvimento mais flexível e intuitivo dos labirintos, podendo colocar o *Pac-man*, os fantasmas e as bolinhas em diversas posições e com tamanhos e formatos variáveis de labirintos. Devido aos requisitos do projeto, foram colocadas as seguintes restrições:\n",
    "\n",
    "- Como o objetivo do problema prioriza a avaliação dos algoritmos, o problema foi modelado com o objetivo mais simples: Encontrar a única bolinha que está presente nos mapas propostos.\n",
    "- Não foram colocadas bolinhas com poderes nos labirintos. Isso dá mais ênfase a busca, pois o *Pac-man* sempre perderá o jogo se o algoritmo escolher o caminho onde está um dos fantasmas.\n",
    "- São colocados 3 fantasmas em posições determinadas, porém distintas.\n",
    "- O agente inteligente dos fantasmas é desligado durante o jogo.\n",
    "- Para simplificar os *layouts* e testes dos algoritmos, o labirinto possui o formato retangular e fechado.\n",
    "- O labirinto é feito em **[6]**, colocado em arquivo e possui um tamanho de 28 linhas x 31 colunas\n",
    "- O *Pac-man* é colocado em uma posição determinada.\n",
    "\n",
    "#### Problema, agentes e ambiente\n",
    "\n",
    "Como o labirinto é representado por um grid, os estados foram representados por tuplas no formato **(x,y)** e as ações são determinadas pelas direções **['South', 'West', 'East', 'North']**. Uma implementação simples do problema na biblioteca AIMA pode ser verificada no código abaixo:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"AIMA Library Representation similar to UC Berkeley code\"\"\"\n",
    "class SimplePacmanProblem(Problem):\n",
    "    def __init__(self, initial=(0, 0), goal=(30, 30), obstacles=(), heuristic=euclidean_distance, **kwds):\n",
    "        Problem.__init__(self, initial=initial, goal=goal, **kwds)\n",
    "        self.obstacles = obstacles - {initial, goal}\n",
    "        self.heuristic = heuristic\n",
    "\n",
    "    directions = [(0, -1), (-1, 0), (1, 0), (0, 1)]\n",
    "\n",
    "    def action_cost(self, s, action, s1): return self.heuristic(s, s1)\n",
    "\n",
    "    def value(self, state): return -1 * np.linalg.norm(self.heuristic(state, self.goal))\n",
    "\n",
    "    def h(self, node): return self.heuristic(node.state, self.goal)\n",
    "\n",
    "    def result(self, state, action):\n",
    "        return action if action not in self.obstacles else state\n",
    "\n",
    "    def actions(self, state):\n",
    "        x, y = state\n",
    "        return {(x + dx, y + dy) for (dx, dy) in self.directions} - self.obstacles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nele, a classe **SimplePacmanProblem** é uma classe filha da classe **Problem**, que é passada para os algoritmos de busca encontrarem o melhor caminho. Como parâmetros em seu construtor há um valor inicial, final, obstáculos e heurística. **action_cost** é a função heurística utilizada para algoritmos de busca informada (ou **g(x)**), **h** é a função heurística utilizada para o *A*\\* (ou **h(x)**) e **value** é a função heurística utilizada para algoritmos de busca locais (ou **g(x)**). No AIMA, o heurística nos algoritmos de busca locais em seu código original é realizada em direção a um mínimo local. O valor de **directions** seria semelhante às ações que o *Pac-man* executaria no caminho, fazendo estados e ações serem tuplas no formato **(x,y)** e praticamente não tendo diferenciação.\n",
    "\n",
    "A classe semelhante no código utilizado neste projeto é a **PositionSearchProblem2**, que é uma classe filha da classe **SearchProblem2**, a qual é passada para os algoritmos de busca encontrarem o melhor caminho. Como parâmetros em seu construtor há um valor inicial, final, heurística e o estado do jogo, que guarda as posições das paredes, fantasmas, das bolinhas e do *Pac-man*. **getCostOfActions** é a função utilizada para determinar os estados através da função heurística para os algoritmos de busca informada e local (dependendo dos parâmetros utilizados pode ser **g(x)** ou **h(x)**). **getSuccessors** é a função que disponibiliza os nós sucessores da busca, semelhante a função **actions** presente na AIMA. Há ainda a função **isGoalState**, semelhante a função **goal_test** da classe **Problem**. A classe **Search2Agent** faz o papel de agente inteligente e a ligação entre problema, algoritmo de busca, estado do jogo e heurística.\n",
    "\n",
    "Um diagrama de classes com todas as classes presentes no código pode ser visto no PDF abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lucas/mo416/MO416AI/Project1\\modelling\\modellingClasses.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This .pdf file shows class diagram that implements how the problem was modeled using game graphical interface. It is part\n",
    "# of how requirement [R4] and requirement [8] was modeling from Berkeley algorithm design base, and modification done\n",
    "# to comply with MO416 Project 1 requirements.\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd=cwd+'\\modelling\\modellingClasses.pdf'\n",
    "print(cwd)\n",
    "import webbrowser\n",
    "#webbrowser.open(r'file:///my_pdf.pdf')\n",
    "webbrowser.open(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmos\n",
    "\n",
    "#### Busca não-informada\n",
    "\n",
    "##### Depth-First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function dfs\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 72 in 0.01837897300720215s\n",
      "Search nodes expanded: 79\n",
      "[R13] Nodes visited: [(23, 29), (22, 29), (21, 29), (20, 29), (19, 29), (18, 29), (17, 29), (16, 29), (15, 29), (14, 29), (13, 29), (12, 29), (11, 29), (10, 29), (9, 29), (8, 29), (7, 29), (6, 29), (5, 29), (4, 29), (3, 29), (2, 29), (1, 29), (1, 28), (1, 27), (1, 26), (1, 25), (1, 24), (1, 23), (1, 22), (1, 21), (1, 20), (2, 20), (3, 20), (4, 20), (5, 20), (6, 20), (6, 19), (6, 18), (6, 17), (6, 16), (5, 16), (4, 16), (3, 16), (2, 16), (1, 16), (1, 17), (1, 18), (1, 19), (3, 15), (3, 14), (3, 13), (2, 13), (1, 13), (1, 12), (1, 11), (1, 10), (2, 10), (3, 10), (3, 9), (3, 8), (3, 7), (2, 7), (1, 7), (4, 7), (5, 7), (6, 7), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R13] Solution states: 73 - [(23, 29), (22, 29), (21, 29), (20, 29), (19, 29), (18, 29), (17, 29), (16, 29), (15, 29), (14, 29), (13, 29), (12, 29), (11, 29), (10, 29), (9, 29), (8, 29), (7, 29), (6, 29), (5, 29), (4, 29), (3, 29), (2, 29), (1, 29), (1, 28), (1, 27), (1, 26), (1, 25), (1, 24), (1, 23), (1, 22), (1, 21), (1, 20), (2, 20), (3, 20), (4, 20), (5, 20), (6, 20), (6, 19), (6, 18), (6, 17), (6, 16), (5, 16), (4, 16), (3, 16), (3, 15), (3, 14), (3, 13), (2, 13), (1, 13), (1, 12), (1, 11), (1, 10), (2, 10), (3, 10), (3, 9), (3, 8), (3, 7), (4, 7), (5, 7), (6, 7), (6, 6), (6, 5), (6, 4), (6, 3), (6, 2), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R14] Solution actions: ['West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'East', 'East', 'East', 'East', 'East', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'South', 'South', 'South', 'East', 'East', 'South', 'South', 'South', 'East', 'East', 'East', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'North', 'North']\n",
      "Pacman emerges victorious! Score: 438\n",
      "Average Score: 438.0\n",
      "Scores:        438.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R1.1] Show dfs (depth first search) method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=dfs -z .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Breadth-First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function bfs\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 48 in 0.044214725494384766s\n",
      "Search nodes expanded: 336\n",
      "[R13] Nodes visited: [(23, 29), (23, 28), (24, 29), (22, 29), (23, 27), (25, 29), (21, 29), (23, 26), (26, 29), (20, 29), (22, 26), (26, 28), (19, 29), (21, 26), (26, 27), (18, 29), (21, 25), (26, 26), (17, 29), (21, 24), (26, 25), (16, 29), (21, 23), (26, 24), (15, 29), (22, 23), (20, 23), (26, 23), (15, 28), (14, 29), (23, 23), (19, 23), (26, 22), (15, 27), (13, 29), (23, 22), (18, 23), (26, 21), (15, 26), (12, 29), (23, 21), (18, 24), (18, 22), (17, 23), (26, 20), (16, 26), (12, 28), (11, 29), (23, 20), (18, 25), (18, 21), (16, 23), (26, 19), (25, 20), (17, 26), (12, 27), (10, 29), (24, 20), (22, 20), (18, 26), (18, 20), (15, 23), (26, 18), (12, 26), (9, 29), (21, 20), (18, 19), (14, 23), (26, 17), (11, 26), (8, 29), (21, 19), (18, 18), (17, 19), (13, 23), (26, 16), (10, 26), (7, 29), (21, 18), (18, 17), (16, 19), (12, 23), (25, 16), (9, 26), (6, 29), (21, 17), (18, 16), (15, 19), (11, 23), (24, 16), (9, 25), (5, 29), (21, 16), (18, 15), (19, 16), (14, 19), (10, 23), (24, 15), (23, 16), (9, 24), (4, 29), (22, 16), (20, 16), (18, 14), (14, 18), (13, 19), (9, 23), (24, 14), (4, 28), (3, 29), (18, 13), (14, 17), (13, 18), (12, 19), (9, 22), (8, 23), (24, 13), (4, 27), (2, 29), (18, 12), (17, 13), (14, 16), (15, 17), (13, 17), (11, 19), (9, 21), (7, 23), (25, 13), (23, 13), (4, 26), (1, 29), (18, 11), (16, 13), (14, 15), (15, 16), (13, 16), (16, 17), (12, 17), (10, 19), (9, 20), (6, 23), (26, 13), (22, 13), (5, 26), (1, 28), (18, 10), (15, 13), (15, 15), (13, 15), (16, 16), (12, 16), (11, 17), (9, 19), (6, 24), (5, 23), (26, 12), (21, 13), (6, 26), (1, 27), (18, 9), (19, 10), (17, 10), (14, 13), (16, 15), (12, 15), (11, 16), (9, 18), (6, 25), (4, 23), (26, 11), (21, 12), (1, 26), (18, 8), (20, 10), (16, 10), (13, 13), (11, 15), (9, 17), (4, 22), (26, 10), (21, 11), (1, 25), (18, 7), (21, 10), (15, 10), (12, 13), (9, 16), (4, 21), (25, 10), (1, 24), (18, 6), (21, 9), (15, 9), (11, 13), (9, 15), (8, 16), (4, 20), (24, 10), (1, 23), (18, 5), (21, 8), (15, 8), (10, 13), (9, 14), (7, 16), (5, 20), (3, 20), (24, 9), (1, 22), (18, 4), (21, 7), (15, 7), (9, 13), (6, 16), (6, 20), (2, 20), (24, 8), (1, 21), (17, 4), (21, 6), (22, 7), (14, 7), (9, 12), (6, 17), (5, 16), (6, 19), (1, 20), (24, 7), (16, 4), (21, 5), (23, 7), (13, 7), (9, 11), (6, 18), (4, 16), (1, 19), (24, 6), (25, 7), (15, 4), (21, 4), (12, 7), (9, 10), (3, 16), (1, 18), (24, 5), (26, 7), (15, 3), (14, 4), (21, 3), (12, 8), (9, 9), (10, 10), (8, 10), (3, 15), (2, 16), (1, 17), (24, 4), (15, 2), (13, 4), (21, 2), (12, 9), (9, 8), (11, 10), (7, 10), (3, 14), (1, 16), (25, 4), (15, 1), (12, 4), (21, 1), (12, 10), (9, 7), (6, 10), (3, 13), (26, 4), (16, 1), (12, 3), (11, 4), (22, 1), (20, 1), (9, 6), (6, 11), (6, 9), (4, 13), (2, 13), (26, 3), (17, 1), (12, 2), (10, 4), (23, 1), (19, 1), (9, 5), (6, 12), (6, 8), (5, 13), (1, 13), (26, 2), (18, 1), (12, 1), (9, 4), (24, 1), (6, 13), (6, 7), (1, 12), (26, 1), (11, 1), (25, 1), (6, 6), (5, 7), (1, 11), (10, 1), (6, 5), (4, 7), (1, 10), (9, 1), (6, 4), (3, 7), (2, 10), (8, 1), (6, 3), (3, 8), (3, 6), (2, 7), (3, 10), (7, 1), (6, 2), (3, 9), (3, 5), (1, 7), (6, 1), (3, 4), (5, 1), (2, 4), (4, 1), (1, 4), (3, 1), (1, 3)]\n",
      "[R13] Solution states: 49 - [(23, 29), (23, 28), (23, 27), (23, 26), (22, 26), (21, 26), (21, 25), (21, 24), (21, 23), (20, 23), (19, 23), (18, 23), (18, 22), (18, 21), (18, 20), (18, 19), (18, 18), (18, 17), (18, 16), (18, 15), (18, 14), (18, 13), (17, 13), (16, 13), (15, 13), (14, 13), (13, 13), (12, 13), (11, 13), (10, 13), (9, 13), (9, 12), (9, 11), (9, 10), (8, 10), (7, 10), (6, 10), (6, 9), (6, 8), (6, 7), (5, 7), (4, 7), (3, 7), (3, 6), (3, 5), (3, 4), (2, 4), (1, 4), (1, 3)]\n",
      "[R14] Solution actions: ['South', 'South', 'South', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'South']\n",
      "Pacman emerges victorious! Score: 462\n",
      "Average Score: 462.0\n",
      "Scores:        462.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R1.2] Show bfs (breadth first search) method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=bfs -z .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca informada\n",
    "\n",
    "##### A*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function astar and [R18] heuristic Manhattan\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "i=1,j=3\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 48 in 0.014639616012573242s\n",
      "Search nodes expanded: 202\n",
      "[R13] Nodes visited: [(23, 29), (23, 28), (22, 29), (23, 27), (21, 29), (23, 26), (20, 29), (22, 26), (19, 29), (21, 26), (18, 29), (21, 25), (17, 29), (21, 24), (16, 29), (21, 23), (15, 29), (20, 23), (15, 28), (14, 29), (19, 23), (15, 27), (13, 29), (18, 23), (15, 26), (12, 29), (18, 22), (17, 23), (12, 28), (11, 29), (18, 21), (16, 23), (12, 27), (10, 29), (18, 20), (15, 23), (12, 26), (9, 29), (18, 19), (14, 23), (11, 26), (8, 29), (18, 18), (17, 19), (13, 23), (10, 26), (7, 29), (18, 17), (16, 19), (12, 23), (9, 26), (6, 29), (18, 16), (15, 19), (11, 23), (9, 25), (5, 29), (18, 15), (14, 19), (10, 23), (9, 24), (4, 29), (18, 14), (14, 18), (13, 19), (9, 23), (4, 28), (3, 29), (18, 13), (14, 17), (13, 18), (12, 19), (9, 22), (8, 23), (4, 27), (2, 29), (18, 12), (17, 13), (14, 16), (13, 17), (11, 19), (9, 21), (7, 23), (4, 26), (1, 29), (18, 11), (16, 13), (14, 15), (13, 16), (12, 17), (10, 19), (9, 20), (6, 23), (1, 28), (18, 10), (15, 13), (13, 15), (12, 16), (11, 17), (9, 19), (5, 23), (1, 27), (18, 9), (17, 10), (14, 13), (12, 15), (11, 16), (9, 18), (4, 23), (1, 26), (18, 8), (16, 10), (13, 13), (11, 15), (9, 17), (4, 22), (1, 25), (18, 7), (15, 10), (12, 13), (9, 16), (4, 21), (1, 24), (18, 6), (15, 9), (11, 13), (9, 15), (8, 16), (4, 20), (1, 23), (18, 5), (15, 8), (10, 13), (9, 14), (7, 16), (3, 20), (1, 22), (18, 4), (15, 7), (9, 13), (6, 16), (2, 20), (1, 21), (17, 4), (14, 7), (9, 12), (5, 16), (1, 20), (16, 4), (13, 7), (9, 11), (4, 16), (1, 19), (15, 4), (12, 7), (9, 10), (3, 16), (1, 18), (15, 3), (14, 4), (9, 9), (8, 10), (3, 15), (2, 16), (1, 17), (13, 4), (9, 8), (7, 10), (3, 14), (1, 16), (12, 4), (9, 7), (6, 10), (3, 13), (12, 3), (11, 4), (9, 6), (6, 9), (2, 13), (10, 4), (9, 5), (6, 8), (1, 13), (9, 4), (6, 7), (1, 12), (6, 6), (5, 7), (1, 11), (6, 5), (4, 7), (1, 10), (6, 4), (3, 7), (6, 3), (3, 6), (2, 7), (3, 5), (1, 7), (3, 4), (2, 4), (1, 4), (1, 3)]\n",
      "[R13] Solution states: 49 - [(23, 29), (23, 28), (23, 27), (23, 26), (22, 26), (21, 26), (21, 25), (21, 24), (21, 23), (20, 23), (19, 23), (18, 23), (18, 22), (18, 21), (18, 20), (18, 19), (18, 18), (18, 17), (18, 16), (18, 15), (18, 14), (18, 13), (17, 13), (16, 13), (15, 13), (14, 13), (13, 13), (12, 13), (11, 13), (10, 13), (9, 13), (9, 12), (9, 11), (9, 10), (8, 10), (7, 10), (6, 10), (6, 9), (6, 8), (6, 7), (5, 7), (4, 7), (3, 7), (3, 6), (3, 5), (3, 4), (2, 4), (1, 4), (1, 3)]\n",
      "[R14] Solution actions: ['South', 'South', 'South', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'South']\n",
      "Pacman emerges victorious! Score: 462\n",
      "Average Score: 462.0\n",
      "Scores:        462.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R2.1] Show A* and Manhattan heuristic method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=astar -z .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function astare and [R18] heuristic Manhattan\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "i=1,j=3\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 48 in 0.017566680908203125s\n",
      "Search nodes expanded: 268\n",
      "[R13] Nodes visited: [(23, 29), (23, 28), (22, 29), (23, 27), (21, 29), (23, 26), (24, 29), (20, 29), (22, 26), (19, 29), (21, 26), (21, 25), (18, 29), (21, 24), (17, 29), (21, 23), (20, 23), (19, 23), (25, 29), (16, 29), (18, 23), (15, 29), (18, 22), (17, 23), (15, 28), (18, 21), (15, 27), (15, 26), (22, 23), (14, 29), (16, 23), (18, 20), (13, 29), (15, 23), (18, 19), (14, 23), (18, 18), (17, 19), (16, 19), (26, 29), (18, 24), (16, 26), (23, 23), (12, 29), (13, 23), (18, 17), (15, 19), (26, 28), (12, 28), (11, 29), (12, 23), (18, 16), (14, 19), (26, 27), (12, 27), (18, 15), (14, 18), (26, 26), (12, 26), (18, 25), (23, 22), (10, 29), (11, 23), (13, 19), (18, 14), (14, 17), (13, 18), (26, 25), (11, 26), (23, 21), (10, 23), (12, 19), (18, 13), (14, 16), (13, 17), (26, 24), (10, 26), (23, 20), (11, 19), (17, 13), (14, 15), (13, 16), (12, 17), (13, 15), (17, 26), (19, 16), (9, 29), (15, 17), (9, 23), (18, 12), (26, 23), (9, 26), (22, 20), (10, 19), (16, 13), (12, 16), (11, 17), (12, 15), (8, 29), (9, 22), (18, 11), (26, 22), (9, 25), (9, 24), (21, 20), (9, 19), (15, 13), (11, 16), (11, 15), (9, 21), (26, 21), (21, 19), (9, 20), (14, 13), (13, 13), (12, 13), (18, 26), (15, 16), (24, 20), (15, 15), (8, 23), (7, 29), (18, 10), (9, 18), (26, 20), (21, 18), (11, 13), (25, 20), (7, 23), (17, 10), (9, 17), (26, 19), (21, 17), (10, 13), (16, 10), (9, 16), (21, 16), (9, 13), (15, 10), (9, 15), (8, 16), (9, 14), (20, 16), (16, 17), (16, 16), (6, 29), (18, 9), (6, 23), (26, 18), (9, 12), (15, 9), (7, 16), (18, 8), (26, 17), (9, 11), (15, 8), (6, 16), (9, 10), (8, 10), (16, 15), (19, 10), (22, 16), (5, 29), (5, 23), (18, 7), (26, 16), (15, 7), (5, 16), (9, 9), (7, 10), (25, 16), (14, 7), (9, 8), (6, 10), (24, 16), (23, 16), (13, 7), (9, 7), (6, 9), (24, 15), (12, 7), (6, 24), (6, 17), (10, 10), (4, 29), (4, 23), (18, 6), (4, 16), (9, 6), (6, 8), (24, 14), (4, 28), (4, 22), (6, 7), (4, 27), (4, 21), (6, 6), (5, 7), (4, 26), (4, 20), (20, 10), (6, 11), (12, 8), (3, 29), (18, 5), (3, 16), (9, 5), (24, 13), (6, 5), (4, 7), (5, 26), (5, 20), (3, 20), (3, 15), (23, 13), (3, 7), (3, 14), (22, 13), (3, 6), (3, 13), (21, 13), (3, 5), (21, 12), (6, 25), (6, 18), (11, 10), (12, 9), (2, 29), (18, 4), (2, 16), (9, 4), (6, 4), (6, 26), (6, 20), (2, 20), (2, 7), (4, 13), (2, 13), (3, 4), (21, 11), (6, 19), (17, 4), (2, 4), (16, 4), (15, 4), (14, 4), (13, 4), (12, 4), (11, 4), (10, 4), (21, 10), (6, 12), (25, 13), (3, 8), (1, 29), (1, 16), (6, 3), (1, 20), (1, 7), (5, 13), (1, 13), (1, 4), (15, 3), (12, 3), (21, 9), (1, 28), (1, 19), (1, 12), (1, 3)]\n",
      "Pacman emerges victorious! Score: 462\n",
      "Average Score: 462.0\n",
      "Scores:        462.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R2.1] Show A* and Euclidean heuristic method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=astare -z .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Greedy Best-First Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function gbfs and [R18] heuristic Manhattan\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "i=1,j=3\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 52 in 0.0048792362213134766s\n",
      "Search nodes expanded: 61\n",
      "[R13] Nodes visited: [(23, 29), (23, 28), (23, 27), (23, 26), (22, 26), (21, 26), (21, 25), (21, 24), (21, 23), (20, 23), (19, 23), (18, 23), (18, 22), (18, 21), (18, 20), (18, 19), (18, 18), (18, 17), (18, 16), (18, 15), (18, 14), (18, 13), (18, 12), (18, 11), (18, 10), (18, 9), (18, 8), (18, 7), (18, 6), (18, 5), (18, 4), (17, 4), (16, 4), (15, 4), (15, 3), (14, 4), (13, 4), (12, 4), (12, 3), (11, 4), (10, 4), (9, 4), (9, 5), (9, 6), (12, 2), (9, 7), (12, 1), (11, 1), (10, 1), (9, 1), (8, 1), (7, 1), (6, 1), (6, 2), (6, 3), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R13] Solution states: 53 - [(23, 29), (23, 28), (23, 27), (23, 26), (22, 26), (21, 26), (21, 25), (21, 24), (21, 23), (20, 23), (19, 23), (18, 23), (18, 22), (18, 21), (18, 20), (18, 19), (18, 18), (18, 17), (18, 16), (18, 15), (18, 14), (18, 13), (18, 12), (18, 11), (18, 10), (18, 9), (18, 8), (18, 7), (18, 6), (18, 5), (18, 4), (17, 4), (16, 4), (15, 4), (14, 4), (13, 4), (12, 4), (12, 3), (12, 2), (12, 1), (11, 1), (10, 1), (9, 1), (8, 1), (7, 1), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R14] Solution actions: ['South', 'South', 'South', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'North', 'North']\n",
      "Pacman emerges victorious! Score: 458\n",
      "Average Score: 458.0\n",
      "Scores:        458.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "#[R2.2] Show gbfs (greedy best first search) and Manhattan heuristic method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=gbfs -z .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function gbfes and [R18] heuristic Manhattan\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "i=1,j=3\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 48 in 0.006834268569946289s\n",
      "Search nodes expanded: 73\n",
      "[R13] Nodes visited: [(23, 29), (23, 28), (23, 27), (23, 26), (22, 26), (21, 26), (21, 25), (21, 24), (21, 23), (20, 23), (19, 23), (18, 23), (18, 22), (18, 21), (18, 20), (18, 19), (18, 18), (17, 19), (16, 19), (15, 19), (14, 19), (14, 18), (14, 17), (14, 16), (14, 15), (13, 15), (12, 15), (11, 15), (11, 16), (13, 16), (12, 16), (11, 17), (12, 17), (13, 17), (15, 15), (13, 18), (15, 17), (15, 16), (16, 15), (16, 16), (13, 19), (12, 19), (11, 19), (10, 19), (9, 19), (9, 18), (9, 17), (9, 16), (9, 15), (9, 14), (9, 13), (9, 12), (9, 11), (9, 10), (8, 10), (7, 10), (6, 10), (6, 9), (6, 8), (6, 7), (6, 6), (5, 7), (6, 5), (4, 7), (3, 7), (3, 6), (3, 5), (3, 4), (2, 4), (1, 4), (1, 3)]\n",
      "Pacman emerges victorious! Score: 462\n",
      "Average Score: 462.0\n",
      "Scores:        462.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "##[R2.2] Show gbfs (greedy best first search) and Euclidean heuristic method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=gbfes -z .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Busca local (*Hill Climbing*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function hcs \n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "i=1,j=3\n",
      "[R12] Initial position of pacman is (23, 29)\n",
      "[R10] Final goal position is (1, 3)\n",
      "[R11] Ghost Positions is/are [(9, 20), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R15] has the game food? True\n",
      "[R16] Path found with total cost g(x) of 70 in 0.022484540939331055s\n",
      "Search nodes expanded: 794\n",
      "[R13] Nodes visited: [(23, 29), (24, 29), (25, 29), (26, 29), (26, 28), (26, 27), (26, 26), (26, 25), (26, 24), (26, 23), (26, 22), (26, 21), (26, 20), (25, 20), (24, 20), (23, 20), (23, 21), (23, 22), (23, 23), (22, 20), (21, 20), (21, 19), (21, 18), (21, 17), (21, 16), (22, 16), (23, 16), (24, 16), (24, 15), (24, 14), (24, 13), (23, 13), (22, 13), (21, 13), (21, 12), (21, 11), (21, 10), (21, 9), (21, 8), (21, 7), (22, 7), (23, 7), (24, 7), (24, 6), (24, 5), (24, 4), (25, 4), (26, 4), (26, 3), (26, 2), (26, 1), (25, 1), (24, 1), (23, 1), (22, 1), (21, 1), (21, 2), (21, 3), (21, 4), (21, 5), (21, 6), (20, 16), (19, 16), (18, 16), (18, 15), (18, 14), (18, 13), (18, 12), (18, 11), (18, 10), (17, 10), (16, 10), (15, 10), (15, 9), (15, 8), (15, 7), (14, 7), (13, 7), (12, 7), (12, 8), (12, 9), (12, 10), (11, 10), (10, 10), (9, 10), (9, 9), (9, 8), (9, 7), (9, 6), (9, 5), (9, 4), (10, 4), (11, 4), (12, 4), (12, 3), (12, 2), (19, 10), (20, 10), (20, 1), (19, 1), (18, 1), (17, 1), (16, 1), (15, 1), (15, 2), (15, 3), (15, 4), (16, 4), (17, 4), (18, 4), (18, 5), (18, 6), (18, 7), (18, 8), (18, 9), (17, 13), (16, 13), (15, 13), (14, 13), (13, 13), (12, 13), (11, 13), (10, 13), (9, 13), (9, 14), (9, 15), (9, 16), (9, 17), (9, 18), (9, 19), (10, 19), (11, 19), (12, 19), (13, 19), (14, 19), (14, 18), (14, 17), (15, 17), (15, 16), (16, 16), (16, 17), (14, 16), (14, 15), (15, 15), (16, 15), (13, 17), (13, 16), (12, 16), (12, 15), (11, 15), (11, 16), (11, 17), (12, 17), (13, 18), (13, 15), (8, 16), (7, 16), (6, 16), (6, 17), (6, 18), (6, 19), (6, 20), (5, 20), (4, 20), (3, 20), (2, 20), (1, 20), (1, 21), (1, 22), (1, 23), (1, 24), (1, 25), (1, 26), (1, 27), (1, 28), (1, 29), (2, 29), (3, 29), (4, 29), (4, 28), (4, 27), (4, 26), (5, 26), (6, 26), (6, 25), (6, 24), (6, 23), (7, 23), (8, 23), (9, 23), (9, 22), (9, 21), (9, 20), (9, 12), (9, 11), (12, 1), (11, 1), (10, 1), (9, 1), (8, 1), (7, 1), (6, 1), (6, 2), (6, 3), (6, 4), (6, 5), (6, 6), (6, 7), (6, 8), (6, 9), (6, 10), (6, 11), (6, 12), (6, 13), (5, 13), (4, 13), (3, 13), (3, 14), (3, 15), (3, 16), (4, 16), (5, 16), (10, 23), (11, 23), (12, 23), (13, 23), (14, 23), (15, 23), (16, 23), (17, 23), (18, 23), (18, 24), (18, 25), (18, 26), (17, 26), (16, 26), (15, 26), (15, 27), (15, 28), (15, 29), (16, 29), (17, 29), (18, 29), (19, 29), (20, 29), (21, 29), (22, 29), (25, 16), (26, 16), (26, 17), (26, 18), (26, 19), (25, 7), (26, 7), (24, 8), (24, 9), (24, 10), (25, 10), (26, 10), (26, 11), (26, 12), (26, 13), (25, 13), (9, 24), (9, 25), (9, 26), (10, 26), (11, 26), (12, 26), (12, 27), (12, 28), (12, 29), (11, 29), (10, 29), (9, 29), (8, 29), (7, 29), (6, 29), (5, 29), (5, 23), (4, 23), (4, 22), (4, 21), (19, 23), (20, 23), (21, 23), (22, 23), (14, 4), (13, 4), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R13] Solution states: 71 - [(23, 29), (24, 29), (25, 29), (26, 29), (26, 28), (26, 27), (26, 26), (26, 25), (26, 24), (26, 23), (26, 22), (26, 21), (26, 20), (25, 20), (24, 20), (23, 20), (22, 20), (21, 20), (21, 19), (21, 18), (21, 17), (21, 16), (20, 16), (19, 16), (18, 16), (18, 15), (18, 14), (18, 13), (18, 12), (18, 11), (18, 10), (17, 10), (16, 10), (15, 10), (15, 9), (15, 8), (15, 7), (14, 7), (13, 7), (12, 7), (12, 8), (12, 9), (12, 10), (11, 10), (10, 10), (9, 10), (9, 9), (9, 8), (9, 7), (9, 6), (9, 5), (9, 4), (10, 4), (11, 4), (12, 4), (12, 3), (12, 2), (12, 1), (11, 1), (10, 1), (9, 1), (8, 1), (7, 1), (6, 1), (5, 1), (4, 1), (3, 1), (2, 1), (1, 1), (1, 2), (1, 3)]\n",
      "[R14] Solution actions: ['East', 'East', 'East', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'West', 'West', 'West', 'South', 'South', 'South', 'West', 'West', 'West', 'North', 'North', 'North', 'West', 'West', 'West', 'South', 'South', 'South', 'South', 'South', 'South', 'East', 'East', 'East', 'South', 'South', 'South', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'West', 'North', 'North']\n",
      "Pacman died! Score: -533\n",
      "Average Score: -533.0\n",
      "Scores:        -533.0\n",
      "Win Rate:      0/1 (0.00)\n",
      "Record:        Loss\n"
     ]
    }
   ],
   "source": [
    "# [R3] Show Hill Climbing Search (hcs) as Local Search method\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=hcs -z .6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografia\n",
    "\n",
    "**[1]** Pac-man - Wikipedia. URL: https://en.wikipedia.org/wiki/Pac-Man\n",
    "\n",
    "**[2]** Project 1. URL: https://drive.google.com/file/d/187lgVekPC0kBmA2AjOm-KkV8Q_lFLeoH/view\n",
    "\n",
    "**[3]** Search for AIMA 4th edition - Implementation of search algorithms and search problems for AIMA. URLs: https://github.com/aimacode/aima-python/blob/master/search4e.ipynb, https://github.com/aimacode/aima-python/blob/master/search.ipynb\n",
    "\n",
    "**[4]** UC Berkeley CS188 Intro to AI -- Course Materials. URL: http://ai.berkeley.edu/search.html\n",
    "\n",
    "**[5]** *tkint* documentation. URL: https://docs.python.org/3/library/tkinter.html\n",
    "\n",
    "**[6]** Pac-Man Maze Generation. URL: https://shaunlebron.github.io/pacman-mazegen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
