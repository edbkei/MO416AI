{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project 1 - Deadline: 04/05/2020\n",
    "\n",
    "# Students:\n",
    "# Eduardo S. Ito RA159086\n",
    "# Jo√£o Paulo RA ....\n",
    "# Lucas Peres RA ....\n",
    "# Thales RA ....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Eduardo\\\\Documents\\\\2020\\\\UNICAMP\\\\MO416A_AI\\\\Project1\\\\Prototype3'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SearchAgent2] using function dfs\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R13] Initial position of pacman is (23, 29)\n",
      "[R11] Final goal position is (1, 3)\n",
      "[R22] Ghost Positions is/are [(9, 17), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R16] has the game food? True\n",
      "[R17] Path found with total cost g(x) of 72 in 0.008976459503173828s\n",
      "Search nodes expanded: 79\n",
      "Pacman emerges victorious! Score: 438\n",
      "Average Score: 438.0\n",
      "Scores:        438.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R1.1] Show dfs (depth first search) method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=dfs -z .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SearchAgent2] using function bfs\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R13] Initial position of pacman is (23, 29)\n",
      "[R11] Final goal position is (1, 3)\n",
      "[R22] Ghost Positions is/are [(9, 17), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R16] has the game food? True\n",
      "[R17] Path found with total cost g(x) of 48 in 0.03789782524108887s\n",
      "Search nodes expanded: 336\n",
      "Pacman emerges victorious! Score: 462\n",
      "Average Score: 462.0\n",
      "Scores:        462.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R1.2] Show bfs (breadth first search) method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=bfs -z .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function astar and [R18] heuristic Manhattan\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R13] Initial position of pacman is (23, 29)\n",
      "[R11] Final goal position is (1, 3)\n",
      "[R22] Ghost Positions is/are [(9, 17), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R16] has the game food? True\n",
      "[R17] Path found with total cost g(x) of 48 in 0.0329127311706543s\n",
      "Search nodes expanded: 202\n",
      "Pacman emerges victorious! Score: 462\n",
      "Average Score: 462.0\n",
      "Scores:        462.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R2.1] Show A* and heuristic method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=astar -z .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function gbfs and [R18] heuristic Manhattan\n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R13] Initial position of pacman is (23, 29)\n",
      "[R11] Final goal position is (1, 3)\n",
      "[R22] Ghost Positions is/are [(9, 17), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R16] has the game food? True\n",
      "[R17] Path found with total cost g(x) of 52 in 0.008960723876953125s\n",
      "Search nodes expanded: 61\n",
      "Pacman emerges victorious! Score: 458\n",
      "Average Score: 458.0\n",
      "Scores:        458.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R2.2] Show gbfs (greedy best first search) and heuristic method.\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=gbfs -z .9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Search2Agent] using function hcs \n",
      "[Search2Agent] using problem type PositionSearchProblem2\n",
      "[R13] Initial position of pacman is (23, 29)\n",
      "[R11] Final goal position is (1, 3)\n",
      "[R22] Ghost Positions is/are [(9, 17), (15, 10), (26, 7)]\n",
      "Number of foods is 1\n",
      "[R16] has the game food? True\n",
      "[R17] Path found with total cost g(x) of 100 in 0.008975028991699219s\n",
      "Search nodes expanded: 146\n",
      "Pacman emerges victorious! Score: 410\n",
      "Average Score: 410.0\n",
      "Scores:        410.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "# [R3] Show Hill Climbing Search (hcs) as Local Search method\n",
    "!python pacman.py -l layoutMO416b -p Search2Agent -a fn=hcs -z .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHAPTER 1: REQUIREMENT SPECIFICATION\n",
    "\n",
    "# 1. Goal\n",
    "\n",
    "# [R1] Two search methods without information\n",
    "# [R2] Two informed search methods with 2 distinct heuristics\n",
    "# [R3] One local search method\n",
    "\n",
    "# The work consists of finding an adequate solution to the chosen problem, evaluating it according to: computational\n",
    "#cost, completeness, optimality. Your are required to clearly define:\n",
    "\n",
    "# [R4] How the problem was modeled\n",
    "# [R5] Implementation specifics and restrictions\n",
    "\n",
    "# The work consists of ending an adequate solution to the chosen problem, evaluating it according to: [R6]computational\n",
    "#cost, [R7] completeness, [R8] optimality. Your are required to clearly define:\n",
    "# [R8] How the problem was modeled\n",
    "# [R5] Implementation specifics and restrictions\n",
    "\n",
    "# 2. Problem\n",
    "# [R24] Pac-man is one of the most popular Arcade games, still played nowadays. In the game, there is a maze where Pac-man\n",
    "# has to act to collect as many pieces as possible without being caught by one of the ghosts. The maze is defined in\n",
    "# terms of a grid, as presented in Figure 1. The black areas are non-traversable walls, the grey path represents elements\n",
    "# that should be caught by the agent, and the white areas are traversable areas. Your group should define additional\n",
    "# elements, such as:\n",
    "\n",
    "# [R10] The size and shape of the maze\n",
    "# [R11] A final goal position\n",
    "# [R12] The static positions of 3 Ghosts in the scene (the positions do not change during the game)\n",
    "# [R13] Pac-man's initial position\n",
    "\n",
    "# To solve the problem, you have to specify:\n",
    "\n",
    "# [R14] The state representation\n",
    "# [R15] The set of actions\n",
    "# [R16] The objective state test\n",
    "# [R17] The cost of the path (g(x))\n",
    "# [R18] The heuristics used\n",
    "\n",
    "# The system must be evaluated according to the quality of the solutions found and a critical evaluation is expected on\n",
    "# the relationship between adopted parameters x solution performance. Graphs and tables representing the evolution of\n",
    "# the solutions are expected. Additional comparisons with the literature are welcome, although they are not mandatory.\n",
    "# To evaluate the results you might change the following elements:\n",
    "\n",
    "# [R19] Pac-man's initial position\n",
    "# [R20] Goal position\n",
    "# [R21] State discretization (maze size and configuration)\n",
    "# [R22] Ghosts' position\n",
    "\n",
    "# [R23] It is important to remember that we will not perform an online search. As the problem is completely observable and\n",
    "# deterministic, Pac-man is going to reason about the solution before actually adopting it.\n",
    "\n",
    "# CHAPTER 2: MODELLING PROPOSAL\n",
    "\n",
    "# Chapter 2.1 [R4] How the Problem was modelled?\n",
    "# The Berkeley algorithm algorithm was used as design base for our implementation.\n",
    "#        [R4.1] Artificial Intelligence in Pacman Class material offered in the course \n",
    "#        \"Artificial Intelligence (2019 Spring) of NTU\" at url https://github.com/andi611/Pacman-With-AI-Python.\n",
    "#        The reason was to comply with [R10]..[R13], it was understood that graphical interface is required, at initial\n",
    "#        stage of project. Despite, the classroom on April 29th, it was clarified that it was not required.\n",
    "#\n",
    "# The reason why requirement [4.2] Python implementation of algorithms from Russell And Norvig's \"Artificial Intelligence\n",
    "#        - A Modern Approach\"  https://github.com/aimacode/aima-python, was not used, is that Berkeley algorithm and Node \n",
    "#        library as used by Russell and Norvig are incompatible. The state used by them differs on coordinate axis\n",
    "#        and the integration of graphical interface and list of actions produced by search algorithm takes very long,\n",
    "#        and could become unfeasible to comply with mostly of requirements. Differences will be explained on this report.\n",
    "#\n",
    "# Our  Project Repository is stored at folder Prototype3 at github address https://github.com/edbkei/MO416AI\n",
    "#\n",
    "# For sake of operationally, the command line inherited \"partly\" by Berkeley algorithm our pacman use cases, do the following: \n",
    "#        !python pacman.py -l layoutMO416b -p Search2Agent -a fn=<fn> -z <z>\n",
    "#        -l layout parameter. We use only the layoutMO416b\n",
    "#        -p agent parameter. We use only Search2Agent as the manager for accessing search methods existing in search2.py,\n",
    "#                            accordingly to problem concept and parameter -a selection.\n",
    "#        -a search method. We use dfs (depth-first search ), ucs (uniform cost search), bfs (breadth-first search), \n",
    "#                          astar (heuristic A*), gbfs (greedy best fisrt search), and hcs (hill climbing search, local search)\n",
    "#        -z zoom. Numberic value (0.1..0.9)\n",
    "#\n",
    "# Conversion from Python 2.7 to Python 3.4. Fix several incompatibility as print format, and library tkint.\n",
    "#\n",
    "# We customized Berkeley algorithm, accordingly to following:\n",
    "#       The implementation of requirement [R10] with maze were done by customization of maze generated by\n",
    "#       https://shaunlebron.github.io/packman-mazegen. We included initial pacman position, only an unique food,\n",
    "#       3 ghosts located in random positions in the maze. Our maze is called layoutMO416b.lay, as the format understood by\n",
    "#       Berkeley format. It is located at ../MO416AI/Prototype3/layout.\n",
    "#       The requirement [R10] is implemented with maze represented by the file. \n",
    "#       The requirement [R10] about size and shape are inherited by Berkeley algorithm. The command parameter -z\n",
    "#       makes zoom possible. \n",
    "#\n",
    "#       The requirement [R11] is implemented as output in search2Agents.py\n",
    "#       The requirement [R12] is implemented by means of pause in the dynamicity of ghost on script pacman.py\n",
    "#       The requirement [R13] is implemented as output in search2Agents.py\n",
    "#       The requirement [R16] is implemented as output in search2Agents.py\n",
    "#       The requirement [R17] is implemented as output in search2Agents.py\n",
    "#       The requirement [R18] is complied with euclidean and Manhattan heuristic from design base, but not used\n",
    "#       in our use cases. We implemented manhattan heuristic (h) for A* and gbfs, in hard code way.\n",
    "#       The original algorithm of A* considers the stop condition f(x)=g(x)+h(x), \n",
    "#       and we did the same algorithm as A* but with f(x) = h(x) for gbfs.We implemented in search2Agents.py and search2.py.\n",
    "#       The hill climbing search was created from the scratch.\n",
    "#\n",
    "#       New function codes to make possible to specify parameter value gbfs and hcs in the command line were introduced. \n",
    "#       Implemented in search2.py.\n",
    "#\n",
    "#      The concept of problem used by Berkeley algorithm is PositionSearchProblem2 (similar to original PositionSearchProblem).\n",
    "#      It is a tuple of (initial state position of the pacman, the goal position of the food, \n",
    "#      action (if next step of pacman is east, west, north, south), cost of 1 for each step in the maze)\n",
    "#\n",
    "#      When a command line is issued, search2Agents is invoked, and according to function code, the PositionSearchProblem2 \n",
    "#      class is invoked to build an actions list produced by search method (in search2.py). Owning this list, \n",
    "#      the class search2Agents can send it to game graphics interface.\n",
    "#      \n",
    "#      For sake of clarity, despite inherited algorithm from Berkeley, the used classes will be represented in class diagram,\n",
    "#      by customization of pyreverse output.\n",
    "#\n",
    "#      And the used search methods are described in high level algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "#webbrowser.open(r'file:///my_pdf.pdf')\n",
    "webbrowser.open(r'classDiagram.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search methods used in search2.py\n",
      "\n",
      "\n",
      "1. Modeling Proposal.\n",
      "\n",
      "function BREADTH_FIRST_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# The aim is to return a list of actions pacman to reach the goal (a food) by\n",
      "# searching the shallowest nodes or states in the search tree first.\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "queue := util.Queue();\n",
      "trace := empty list;\n",
      "seenList := empty list;\n",
      "\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "initial push on queue with start_state;\n",
      "Append (start_state) into seenList;\n",
      "\n",
      "while queue is not empty do\n",
      "\n",
      "   current_state := pop from queue;\n",
      "   \n",
      "   if goal state from problem is reached at current_state then  \n",
      "      break;\n",
      "   end if;\n",
      "   \n",
      "   successors := getSucccessors(current_state) from problem;\n",
      "   \n",
      "   for successor in successors do\n",
      "       next_state := state of successor;\n",
      "\t   next_action := action of successor;\n",
      "\t   \n",
      "\t   if next_state not in seenList then\n",
      "\t      Append(next_state) into seenList;\n",
      "\t\t  push(next_state) into queue;\n",
      "\t\t  trace[next_state] := with tuple (current_state, next_action);\n",
      "\t   end if;\n",
      "\n",
      "   end for;\n",
      "   \n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action := trace[backtrack_state];\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "function DEPTH_FIRST_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# The aim is to return a list of actions pacman to reach the goal (a food) by\n",
      "# searching the deepest nodes in the search tree first.\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "stack := get util.Stack();\n",
      "trace := get util.Stack();\n",
      "\n",
      "traveledList is empty initially;\n",
      "step_counter := 0\n",
      "\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "initial push stack with tuple (start_state, step_counter, 'START')\n",
      "\n",
      "while stack is not empty do\n",
      "   current_state, _, action := pop from stack;\n",
      "   Append (current_state) into traveledList;\n",
      "   \n",
      "   if action is not 'START' then\n",
      "      push (action) into trace list;\n",
      "\t  step_counter := step_counter + 1;\n",
      "   end if;\n",
      "   \n",
      "   if goal state from problem is reached at current_state then  \n",
      "      return trace list;\n",
      "   end if;\n",
      "   \n",
      "   valid_successors := 0;\n",
      "   successors := getSucccessors(current_state) from problem;\n",
      "   \n",
      "   for successor in successors do\n",
      "       next_state := state of successor;\n",
      "\t   next_action := action of successor;\n",
      "\t   \n",
      "\t   if next_state not in traveledList then\n",
      "\t      valid_successors := valid_successors + 1;\n",
      "\t\t  push the tuple (next_state, step_counter, next_action) into stack;\n",
      "\t   end if;\n",
      "   end for;\n",
      "   \n",
      "   if valid_successors is zero then\n",
      "      while step_counter is not stackList[-1][1] # back until next awaiting state do\n",
      "\t      setp_counter := step_counter - 1;\n",
      "\t\t  pop from trace list;\n",
      "\t  end while;\n",
      "   end if;\n",
      "\n",
      "end while\n",
      "}\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "function A_STAR_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# the pacman goal is to get the food at n-interactions with cost f(n) = h(n)\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "openList := class PriorityQueue();\n",
      "g := empty list; # step cost\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "Define function f(current_state) returns g[current_state] + manhattanHeuristic(current_state, problem);\n",
      "g[start_state] := 0; # cost 0 initially\n",
      "Push(start_state, 0) into openList;\n",
      "start openSeen list;\n",
      "close_list := empty list;\n",
      "trace := empty list;\n",
      "trace[start_state] := a tuple with [None, None, 0]\n",
      "\n",
      "while openList is not empty do\n",
      "    current_state := get popping open_list;\n",
      "\tremove (current_state) from openSeen list;\n",
      "\tif goal in problem is reached at current_state then break;\n",
      "\t\n",
      "\tsuccessors := getSuccessors from current_state in problem;\n",
      "\t\n",
      "\tfor successor in successors do\n",
      "\t    next_state := state from successor;\n",
      "\t\tnext_action = action from successor;\n",
      "\t\tnext_cost := cost from successor;\n",
      "\t\tsuccessor_cost := g[current_state] + next_cost;\n",
      "\t\t\n",
      "\t    UPDATE status := False;\n",
      "\t\tif next_state in openSeen list do\n",
      "\t\t   if g[next_state] =< successor_cost then pass;\n",
      "\t\t   else do\n",
      "\t\t           g[next_state] =< successor_cost;\n",
      "\t\t\t\t   Update openList with item=next_state and priority=f(next_state);\n",
      "\t\t        end do \n",
      "\t\t   else if next_state in close_list do\n",
      "\t\t        if g[next_state] =< successor_cost then pass;\n",
      "\t\t\t\telse UPDATE status := True;\n",
      "\t\t\t\tend if\n",
      "\t\t   else: UDPATE status := True\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\tif UPDATE status is True then\n",
      "\t\t   g[next_state] := succcessor_cost;\n",
      "\t\t   openList update with item=next_state and priority=f(next_state)\n",
      "\t\t   Append (next) into openSeen;\n",
      "\t\t   \n",
      "\t\t   if next_state in close_list then\n",
      "\t\t      remove(next_state) from close_list;\n",
      "\t\t\t  remove(next_state) from openSeen\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t# update and allow tracing to the best state\n",
      "\t\tif next_state in trace then\n",
      "\t\t   if cost in trace[next_state] > successor_cost then\n",
      "\t\t      trace[next_state] state := current_state;\n",
      "\t\t\t  trace[next_state] := next_action;\n",
      "\t\t\t  trace[next_state] cost := successor_cost;\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t\n",
      "\tend for;\n",
      "\t\n",
      "\tAppend(current_state) into close_list;\n",
      "\n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "-----------------------------------------------------------------------------------\n",
      "function GREEDY_BEST_FIRST_SEARCH(problem) returns a list of actions towards the pacman goal {\n",
      "# the pacman goal is to get the food at n-interactions with cost f(n) = g(n) + h(n)\n",
      "#\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (a node) and next_state (a neighbor node)\n",
      "\n",
      "openList := class PriorityQueue();\n",
      "g := empty list; # step cost\n",
      "start_state := CREATE-NODE(START-STATE[problem]);\n",
      "Define function f(current_state) returns manhattanHeuristic(current_state, problem);  # difference from A* is only here\n",
      "g[start_state] := 0; # cost 0 initially\n",
      "Push(start_state, 0) into openList;\n",
      "start openSeen list;\n",
      "close_list := empty list;\n",
      "trace := empty list;\n",
      "trace[start_state] := a tuple with [None, None, 0]\n",
      "\n",
      "while openList is not empty do\n",
      "    current_state := get popping open_list;\n",
      "\tremove (current_state) from openSeen list;\n",
      "\tif goal in problem is reached at current_state then break;\n",
      "\t\n",
      "\tsuccessors := getSuccessors from current_state in problem;\n",
      "\t\n",
      "\tfor successor in successors do\n",
      "\t    next_state := state from successor;\n",
      "\t\tnext_action = action from successor;\n",
      "\t\tnext_cost := cost from successor;\n",
      "\t\tsuccessor_cost := g[current_state] + next_cost;\n",
      "\t\t\n",
      "\t    UPDATE status := False;\n",
      "\t\tif next_state in openSeen list do\n",
      "\t\t   if g[next_state] =< successor_cost then pass;\n",
      "\t\t   else do\n",
      "\t\t           g[next_state] =< successor_cost;\n",
      "\t\t\t\t   Update openList with item=next_state and priority=f(next_state);\n",
      "\t\t        end do \n",
      "\t\t   else if next_state in close_list do\n",
      "\t\t        if g[next_state] =< successor_cost then pass;\n",
      "\t\t\t\telse UPDATE status := True;\n",
      "\t\t\t\tend if\n",
      "\t\t   else: UDPATE status := True\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\tif UPDATE status is True then\n",
      "\t\t   g[next_state] := succcessor_cost;\n",
      "\t\t   openList update with item=next_state and priority=f(next_state)\n",
      "\t\t   Append (next) into openSeen;\n",
      "\t\t   \n",
      "\t\t   if next_state in close_list then\n",
      "\t\t      remove(next_state) from close_list;\n",
      "\t\t\t  remove(next_state) from openSeen\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t# update and allow tracing to the best state\n",
      "\t\tif next_state in trace then\n",
      "\t\t   if cost in trace[next_state] > successor_cost then\n",
      "\t\t      trace[next_state] state := current_state;\n",
      "\t\t\t  trace[next_state] := next_action;\n",
      "\t\t\t  trace[next_state] cost := successor_cost;\n",
      "\t\t   end if;\n",
      "\t\tend if;\n",
      "\t\t\n",
      "\t\t\n",
      "\tend for;\n",
      "\t\n",
      "\tAppend(current_state) into close_list;\n",
      "\n",
      "end while\n",
      "\n",
      "actions list := empty list;\n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_state do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) into actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n",
      "\n",
      "-----------------------------------------------------------------------------------\n",
      "\n",
      "function HILL-CLIMBING(problem) returns a list of actions towards the pacman goal {\n",
      "# the top of hill is the pacman goal\n",
      "input: problem (a tuple of start_state, action, cost, goalState)\n",
      "# node or state has the same meaning for pacman game\n",
      "local variables: current_state (current node) and next_state (a neighbor)\n",
      "priority_queue := class PriorityQueue();\n",
      "priority_queue.update(start_state);\n",
      "current_state := CREATE-NODE(START-STATE[problem]);\n",
      "prev_cost := 0;\n",
      "trace[start_state] := tuple of (none state, none action, prev_cost)\n",
      "veryPreviousSuccessor:=empty;\n",
      "prevsuccessor := empty; # previous successor;\n",
      "\n",
      "while not priority_queue.isEmpty do\n",
      "   current_state := priority_queue.pop();\n",
      "   \n",
      "   if problem goal is current_state state then end while;\n",
      "   \n",
      "   successors := problem.getSuccessors(current_state); # a pacman sucessor can be \n",
      "                             # any next position at North, South, \n",
      "\t\t\t                 # East, West. Making sure  that                 \n",
      "\t\t                     # previous position is not allowed.\n",
      "\t\t\t\t\t\t     # and if there are more than one of successors \n",
      "\t\t\t\t\t\t\t # is selected at random, as cost of any \n",
      "\t\t\t\t\t\t\t # step in pacman is unique.\n",
      "   \n",
      "\tt := length of successors # amount of successors;\n",
      "\tselectedSuccessor=[];\n",
      "\tif t is 1, i.e. unique successor then\n",
      "\t   index := 0;\n",
      "\t   selectedSuccessor := successors;\n",
      "\telse\n",
      "\t   i := 0;\n",
      "\n",
      "\t while True:\n",
      "\t   i := i+1;\n",
      "\t   index := choose at random in between 0 and t-1;\n",
      "\t   if previousSuccessor is [] then\n",
      "\t      selectedSuccessor := successors[index];\n",
      "\t\t  prevsuccessor := selectedSuccessor;\n",
      "\t\t  break;\n",
      "\t   if state in successors[index] not equal to state in previousSuccessor then\n",
      "\t      if (not(action='East' in successors[index] and action='West' in previousSuccessor[index]\n",
      "\t\t       or action='West' in successors[index] and action='East' in previousSuccessor[index]\n",
      "\t\t\t   or action='South' in successors[index] and action='North' in previousSuccessor[index]\n",
      "\t\t\t   or action='North' in successors[index] and action='South' in previousSuccessor[index]))\n",
      "\t\t\t   then \n",
      "\t\t\t       selectedSuccessor := successors[index];\n",
      "\t\t\t\t   previousSuccessor := selectedSuccessor;\n",
      "\t\t\t\t   break; # exit from while True\n",
      "       if (i>5) then # if more than 5 attempts\n",
      "\t      index := get a number at random in between 0 and t-1; # choose a successor at random\n",
      "\t\t  selectedSuccessor := successors[index];\n",
      "\t\t  previousSuccessor := selectedSuccessor;\n",
      "\t\n",
      "\t for successor in selectedSuccessor do\n",
      "\t\tnext_state = state of successor; # node\n",
      "\t\tnext_action = action of successor; # if west, east, north, sourth\n",
      "\t\tnext_cost = cost of successor; # always 1\n",
      "\t     \n",
      "\t\tif veryPreviousSuccessor is empty then \n",
      "\t\t   veryPreviousSuccessor := successor;\n",
      "\t\t   prev_cost := cost of trace[current_state];\n",
      "\t\t   priority_queue update with next_state;\n",
      "\t\telse if (not(action='East' in successors[index] and action='West' in previousSuccessor[index]\n",
      "\t\t       or action='West' in successors[index] and action='East' in previousSuccessor[index]\n",
      "\t\t\t   or action='South' in successors[index] and action='North' in previousSuccessor[index]\n",
      "\t\t\t   or action='North' in successors[index] and action='South' in previousSuccessor[index]))\n",
      "\t\t\t   then\n",
      "\t\t\t      veryPreviousSuccessor := successor;\n",
      "\t\t\t\t  prev_cost := cost of trace[current_state];\n",
      "\t\t\t\t  priority_queue update with next_state;\n",
      "\t\tend if\n",
      "\t\t\t\t  \n",
      "\t\tif next_state is not in the trace then\n",
      "\t\t   trace[next_state] := tuple of [current_state, next_action, 1]\n",
      "\t\tend if\n",
      "\tend while\n",
      "end while\n",
      "\n",
      "actions list := an empty list;\t   \n",
      "backtrack_state := current_state;\n",
      "\n",
      "while backtrack_state is not start_start do\n",
      "     prev_state, action, _ := trace[backtrack_state]\n",
      "\t append (action) to actions list;\n",
      "\t backtrack_state := prev_state;\n",
      "end while\n",
      "\n",
      "actions list := reverse the actions list;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Methods used in search2.py\n",
    "print(\"Search methods used in search2.py\")\n",
    "f = open('modelingProposal', 'r')\n",
    "file_contents = f.read()\n",
    "print (file_contents)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
